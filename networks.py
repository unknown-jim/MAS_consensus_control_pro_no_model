"""
ç¥ç»ç½‘ç»œæ¨¡å‹ - CTDE æ¶æ„ç‰ˆæœ¬

CTDE = Centralized Training Decentralized Execution
- Actor: åˆ†æ•£å¼ï¼Œåªä½¿ç”¨æœ¬åœ°è§‚æµ‹
- Critic: é›†ä¸­å¼ï¼Œä½¿ç”¨å…¨å±€çŠ¶æ€ + æ‰€æœ‰æ™ºèƒ½ä½“åŠ¨ä½œ
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.distributions import Normal
import math

from config import (
    STATE_DIM, HIDDEN_DIM, ACTION_DIM,
    LOCAL_OBS_DIM, NEIGHBOR_OBS_DIM, MAX_NEIGHBORS,
    SELF_ROLE_DIM, NEIGHBOR_ROLE_DIM, NEIGHBOR_FEAT_DIM,
    LOG_STD_MIN, LOG_STD_MAX, V_SCALE, TH_SCALE,
    NUM_ATTENTION_HEADS, NUM_TRANSFORMER_LAYERS, DROPOUT,
    LIGHTWEIGHT_MODE, NUM_FOLLOWERS, GLOBAL_STATE_DIM
)


# ============================================================
# æ³¨æ„åŠ›æ¨¡å—ï¼ˆä¸åŸç‰ˆç›¸åŒï¼‰
# ============================================================

class LightweightAttention(nn.Module):
    """è½»é‡çº§æ³¨æ„åŠ›æ¨¡å—"""
    
    def __init__(self, dim, num_heads=2, dropout=0.05):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = dim // num_heads
        self.scale = self.head_dim ** -0.5
        
        self.qkv = nn.Linear(dim, dim * 3, bias=False)
        self.proj = nn.Linear(dim, dim)
        self.dropout = nn.Dropout(dropout)
        
        self.ffn = nn.Sequential(
            nn.Linear(dim, dim * 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(dim * 2, dim),
            nn.Dropout(dropout)
        )
        
        self.norm1 = nn.LayerNorm(dim)
        self.norm2 = nn.LayerNorm(dim)
    
    def forward(self, x, mask=None):
        batch_size, seq_len, dim = x.shape
        
        residual = x
        x = self.norm1(x)
        
        qkv = self.qkv(x).reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)
        qkv = qkv.permute(2, 0, 3, 1, 4)
        q, k, v = qkv[0], qkv[1], qkv[2]
        
        attn = torch.matmul(q, k.transpose(-2, -1)) * self.scale
        
        if mask is not None:
            mask_expanded = mask.unsqueeze(1).unsqueeze(2)
            attn = attn.masked_fill(mask_expanded, float('-inf'))
        
        attn = F.softmax(attn, dim=-1)
        attn = torch.nan_to_num(attn, nan=0.0)
        attn = self.dropout(attn)
        
        out = torch.matmul(attn, v)
        out = out.transpose(1, 2).reshape(batch_size, seq_len, dim)
        out = self.proj(out)
        
        x = residual + out
        x = x + self.ffn(self.norm2(x))
        
        return x


class LightweightAttentionEncoder(nn.Module):
    """è½»é‡ç‰ˆæ³¨æ„åŠ›ç¼–ç å™¨"""
    
    def __init__(self, neighbor_dim, hidden_dim, num_heads, num_layers, dropout):
        super().__init__()
        
        self.neighbor_embed = nn.Sequential(
            nn.Linear(neighbor_dim, hidden_dim),
            nn.GELU(),
            nn.LayerNorm(hidden_dim)
        )
        
        self.pos_embed = nn.Parameter(torch.randn(1, MAX_NEIGHBORS, hidden_dim) * 0.02)
        
        self.attention_layers = nn.ModuleList([
            LightweightAttention(hidden_dim, num_heads, dropout)
            for _ in range(num_layers)
        ])
        
        self.output_proj = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
    
    def forward(self, neighbor_data, neighbor_mask=None):
        h = self.neighbor_embed(neighbor_data)
        h = h + self.pos_embed
        
        for layer in self.attention_layers:
            h = layer(h, neighbor_mask)
        
        if neighbor_mask is not None:
            valid_mask = ~neighbor_mask
            valid_count = valid_mask.sum(dim=1, keepdim=True).clamp(min=1).unsqueeze(-1)
            h = (h * valid_mask.unsqueeze(-1)).sum(dim=1) / valid_count.squeeze(-1)
        else:
            h = h.mean(dim=1)
        
        return self.output_proj(h)


# ============================================================
# Actor ç½‘ç»œï¼ˆåˆ†æ•£å¼æ‰§è¡Œ - åªç”¨æœ¬åœ°è§‚æµ‹ï¼‰
# ============================================================

class DecentralizedActor(nn.Module):
    """åˆ†æ•£å¼ Actorï¼ˆç”¨äºæ‰§è¡Œé˜¶æ®µï¼‰ã€‚

    è¾“å…¥ï¼šå•ä¸ªæ™ºèƒ½ä½“çš„æœ¬åœ°è§‚æµ‹
    - è‡ªèº«è§‚æµ‹ (LOCAL_OBS_DIM) + è‡ªèº«è§’è‰² (SELF_ROLE_DIM)
    - é‚»å±…æ•°æ®: MAX_NEIGHBORS Ã— (NEIGHBOR_OBS_DIM + NEIGHBOR_ROLE_DIM)
      ï¼ˆå½“å‰å®ç°é‡Œ NEIGHBOR_ROLE_DIM=0ï¼Œé‚»å±…å¹¿æ’­åŒ…åŒ…å«é‚»å±…è‡ªèº«çŠ¶æ€ + leader ä¼°è®¡ seq/ageï¼‰

    è¾“å‡ºï¼šå•ä¸ªæ™ºèƒ½ä½“çš„åŠ¨ä½œï¼ˆé€Ÿåº¦æ”¹å˜é‡ + é€šä¿¡é˜ˆå€¼ï¼‰

    è¯´æ˜ï¼šä¸ºäº†æ”¯æŒ MAPPO/PPOï¼Œæˆ‘ä»¬é¢å¤–æä¾›â€œç»™å®šåŠ¨ä½œæ±‚ log_probâ€çš„èƒ½åŠ›ã€‚
    """
    
    def __init__(self, local_dim=LOCAL_OBS_DIM, role_dim=SELF_ROLE_DIM,
                 neighbor_dim=NEIGHBOR_OBS_DIM, neighbor_role_dim=NEIGHBOR_ROLE_DIM,
                 hidden_dim=HIDDEN_DIM):
        super().__init__()
        
        self.local_dim = local_dim
        self.role_dim = role_dim
        self.neighbor_obs_dim = neighbor_dim
        self.neighbor_role_dim = neighbor_role_dim
        self.neighbor_feat_dim = neighbor_dim + neighbor_role_dim  # = NEIGHBOR_FEAT_DIM
        
        # æœ¬åœ°çŠ¶æ€ç¼–ç ï¼ˆä½ç½®+é€Ÿåº¦+è§’è‰²ï¼‰
        self.local_encoder = nn.Sequential(
            nn.Linear(local_dim + role_dim, hidden_dim),
            nn.GELU(),
            nn.LayerNorm(hidden_dim)
        )
        
        # é‚»å±…ä¿¡æ¯ç¼–ç ï¼ˆä½ç½®+é€Ÿåº¦+è§’è‰²ï¼‰
        self.neighbor_encoder = LightweightAttentionEncoder(
            self.neighbor_feat_dim, hidden_dim, NUM_ATTENTION_HEADS, 
            NUM_TRANSFORMER_LAYERS, DROPOUT
        )
        
        # èåˆå±‚
        self.fusion = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.GELU(),
            nn.LayerNorm(hidden_dim)
        )
        
        # ç­–ç•¥å¤´
        self.shared = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.GELU()
        )
        
        # é€Ÿåº¦æ”¹å˜é‡å¤´
        self.v_mean = nn.Linear(hidden_dim // 2, 1)
        self.v_log_std = nn.Linear(hidden_dim // 2, 1)
        
        # é˜ˆå€¼å¤´
        self.th_mean = nn.Linear(hidden_dim // 2, 1)
        self.th_log_std = nn.Linear(hidden_dim // 2, 1)
        
        self.v_scale = V_SCALE
        self.th_scale = TH_SCALE
        self._eps = 1e-6
        
        self._log_v_scale = torch.log(torch.tensor(self.v_scale))
        self._log_th_scale = torch.log(torch.tensor(self.th_scale))
        
        self._init_weights()
    
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.orthogonal_(m.weight, gain=0.01)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
    
    def compute_action_params(self, local_obs, self_role, neighbor_data, neighbor_mask=None):
        """è¿”å›åŠ¨ä½œåˆ†å¸ƒå‚æ•°ï¼ˆç”¨äº PPO/MAPPO è¯„ä¼°ç»™å®šåŠ¨ä½œçš„ log_probï¼‰ã€‚

        Returns:
            v_mean, v_log_std, th_mean, th_log_std: shape (batch, 1)
        """
        local_with_role = torch.cat([local_obs, self_role], dim=-1)
        local_feat = self.local_encoder(local_with_role)

        neighbor_feat = self.neighbor_encoder(neighbor_data, neighbor_mask)
        combined = torch.cat([local_feat, neighbor_feat], dim=-1)
        hidden = self.fusion(combined)

        shared_feat = self.shared(hidden)

        v_mean = self.v_mean(shared_feat)
        v_log_std = torch.clamp(self.v_log_std(shared_feat), LOG_STD_MIN, LOG_STD_MAX)

        th_mean = self.th_mean(shared_feat)
        th_log_std = torch.clamp(self.th_log_std(shared_feat), LOG_STD_MIN, LOG_STD_MAX)

        return v_mean, v_log_std, th_mean, th_log_std

    def forward(self, local_obs, self_role, neighbor_data, neighbor_mask=None, deterministic=False):
        """é‡‡æ ·åŠ¨ä½œå¹¶è¿”å› log_probï¼ˆSAC/MAPPO å…±ç”¨ï¼‰ã€‚"""
        v_mean, v_log_std, th_mean, th_log_std = self.compute_action_params(
            local_obs, self_role, neighbor_data, neighbor_mask
        )

        v_std = torch.exp(v_log_std)
        th_std = torch.exp(th_log_std)

        if deterministic:
            v = torch.tanh(v_mean) * self.v_scale
            th = torch.sigmoid(th_mean) * self.th_scale
            log_prob = None
        else:
            v_dist = Normal(v_mean, v_std)
            th_dist = Normal(th_mean, th_std)

            v_sample = v_dist.rsample()
            th_sample = th_dist.rsample()

            v_tanh = torch.tanh(v_sample)
            v = v_tanh * self.v_scale

            th_sigmoid = torch.sigmoid(th_sample)
            th = th_sigmoid * self.th_scale

            log_prob_v = v_dist.log_prob(v_sample) - torch.log(
                torch.clamp(1.0 - v_tanh.pow(2), min=self._eps, max=1.0)
            ) - self._log_v_scale.to(v.device)

            log_prob_th = th_dist.log_prob(th_sample) - torch.log(
                torch.clamp(th_sigmoid * (1.0 - th_sigmoid), min=self._eps, max=0.25)
            ) - self._log_th_scale.to(th.device)

            log_prob = (log_prob_v + log_prob_th).sum(dim=-1, keepdim=True)

        action = torch.cat([v, th], dim=-1)
        return action, log_prob


# ============================================================
# Critic ç½‘ç»œï¼ˆé›†ä¸­å¼è®­ç»ƒ - ä½¿ç”¨å…¨å±€ä¿¡æ¯ï¼‰
# ============================================================

class CentralizedCritic(nn.Module):
    """
    é›†ä¸­å¼ Criticï¼ˆç”¨äºè®­ç»ƒé˜¶æ®µï¼‰
    
    è¾“å…¥ï¼š
    - å…¨å±€çŠ¶æ€ï¼šæ‰€æœ‰æ™ºèƒ½ä½“çš„çœŸå®ä½ç½®å’Œé€Ÿåº¦
    - è”åˆåŠ¨ä½œï¼šæ‰€æœ‰è·Ÿéšè€…çš„åŠ¨ä½œ
    
    è¾“å‡ºï¼šQ å€¼
    """
    
    def __init__(self, global_state_dim=GLOBAL_STATE_DIM, 
                 num_followers=NUM_FOLLOWERS,
                 action_dim=ACTION_DIM, 
                 hidden_dim=HIDDEN_DIM):
        super().__init__()
        
        self.global_state_dim = global_state_dim
        self.num_followers = num_followers
        self.action_dim = action_dim
        self.joint_action_dim = num_followers * action_dim
        
        # å…¨å±€çŠ¶æ€ç¼–ç å™¨
        self.state_encoder = nn.Sequential(
            nn.Linear(global_state_dim, hidden_dim),
            nn.GELU(),
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.GELU(),
            nn.LayerNorm(hidden_dim)
        )
        
        # è”åˆåŠ¨ä½œç¼–ç å™¨
        self.action_encoder = nn.Sequential(
            nn.Linear(self.joint_action_dim, hidden_dim),
            nn.GELU(),
            nn.LayerNorm(hidden_dim)
        )
        
        # Q ç½‘ç»œ
        self.q_net = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.GELU(),
            nn.Linear(hidden_dim // 2, 1)
        )
        
        self._init_weights()
    
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.orthogonal_(m.weight, gain=1.0)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
    
    def forward(self, global_state, joint_action):
        """
        Args:
            global_state: (batch, global_state_dim) - å…¨å±€çŠ¶æ€
            joint_action: (batch, num_followers * action_dim) - è”åˆåŠ¨ä½œ
        
        Returns:
            q_value: (batch, 1)
        """
        state_feat = self.state_encoder(global_state)
        action_feat = self.action_encoder(joint_action)
        combined = torch.cat([state_feat, action_feat], dim=-1)
        return self.q_net(combined)


class CentralizedValue(nn.Module):
    """é›†ä¸­å¼ Value ç½‘ç»œï¼ˆCTDE-MAPPO ç”¨ï¼‰ã€‚

    è¾“å…¥ï¼šglobal_state
    è¾“å‡ºï¼šV(global_state)
    """

    def __init__(self, global_state_dim=GLOBAL_STATE_DIM, hidden_dim=HIDDEN_DIM):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(global_state_dim, hidden_dim),
            nn.GELU(),
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.GELU(),
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, 1),
        )

    def forward(self, global_state):
        return self.net(global_state)


# ============================================================
# å…¼å®¹æ—§æ¥å£çš„åŒ…è£…å™¨
# ============================================================

class GaussianActor(nn.Module):
    """å…¼å®¹æ—§æ¥å£çš„ Actor åŒ…è£…å™¨ï¼ˆåˆ†æ•£å¼ï¼‰ã€‚

    é¢å¤–æ”¯æŒï¼šç»™å®šåŠ¨ä½œè®¡ç®— log_probï¼ˆPPO/MAPPO éœ€è¦ï¼‰ã€‚
    """

    def __init__(self, state_dim=STATE_DIM, hidden_dim=HIDDEN_DIM, num_heads=4):
        super().__init__()
        self.actor = DecentralizedActor(
            LOCAL_OBS_DIM, SELF_ROLE_DIM,
            NEIGHBOR_OBS_DIM, NEIGHBOR_ROLE_DIM,
            hidden_dim
        )
        self.local_dim = LOCAL_OBS_DIM
        self.role_dim = SELF_ROLE_DIM
        self.neighbor_feat_dim = NEIGHBOR_FEAT_DIM
        self.max_neighbors = MAX_NEIGHBORS
        self._eps = 1e-6

    @staticmethod
    def _atanh(x: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:
        x = x.clamp(min=-1.0 + eps, max=1.0 - eps)
        return 0.5 * (torch.log1p(x) - torch.log1p(-x))

    @staticmethod
    def _logit(p: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:
        p = p.clamp(min=eps, max=1.0 - eps)
        return torch.log(p) - torch.log1p(-p)

    def _parse_state(self, state: torch.Tensor):
        local_obs = state[:, :self.local_dim]
        self_role = state[:, self.local_dim:self.local_dim + self.role_dim]
        neighbor_start = self.local_dim + self.role_dim
        neighbor_data = state[:, neighbor_start:].view(-1, self.max_neighbors, self.neighbor_feat_dim)
        neighbor_mask = (neighbor_data.abs().sum(dim=-1) == 0)
        return local_obs, self_role, neighbor_data, neighbor_mask

    def forward(self, state, edge_index=None, role_ids=None, deterministic=False):
        """é‡‡æ ·åŠ¨ä½œå¹¶è¿”å› log_probï¼ˆä¸æ—§æ¥å£å…¼å®¹ï¼‰ã€‚"""
        local_obs, self_role, neighbor_data, neighbor_mask = self._parse_state(state)
        action, log_prob = self.actor(local_obs, self_role, neighbor_data, neighbor_mask, deterministic)
        return action, log_prob, None

    def evaluate_actions(self, state: torch.Tensor, action: torch.Tensor):
        """ç»™å®šåŠ¨ä½œè®¡ç®— log_probã€‚

        Args:
            state: (batch, state_dim)
            action: (batch, ACTION_DIM)

        Returns:
            log_prob: (batch, 1)
        """
        local_obs, self_role, neighbor_data, neighbor_mask = self._parse_state(state)

        v_mean, v_log_std, th_mean, th_log_std = self.actor.compute_action_params(
            local_obs, self_role, neighbor_data, neighbor_mask
        )
        v_std = torch.exp(v_log_std)
        th_std = torch.exp(th_log_std)

        # åè§£ pre-squash å˜é‡
        v = action[:, 0:1]
        th = action[:, 1:2]

        v_tanh = (v / float(self.actor.v_scale)).clamp(-1.0 + self._eps, 1.0 - self._eps)
        th_sigmoid = (th / float(self.actor.th_scale)).clamp(self._eps, 1.0 - self._eps)

        v_pre = self._atanh(v_tanh, eps=self._eps)
        th_pre = self._logit(th_sigmoid, eps=self._eps)

        v_dist = Normal(v_mean, v_std)
        th_dist = Normal(th_mean, th_std)

        log_prob_v = v_dist.log_prob(v_pre) - torch.log(
            torch.clamp(1.0 - v_tanh.pow(2), min=self._eps, max=1.0)
        ) - self.actor._log_v_scale.to(v.device)

        log_prob_th = th_dist.log_prob(th_pre) - torch.log(
            torch.clamp(th_sigmoid * (1.0 - th_sigmoid), min=self._eps, max=0.25)
        ) - self.actor._log_th_scale.to(th.device)

        log_prob = (log_prob_v + log_prob_th).sum(dim=-1, keepdim=True)
        return log_prob


class SoftQNetwork(nn.Module):
    """å…¼å®¹æ—§æ¥å£çš„ Critic åŒ…è£…å™¨ï¼ˆé›†ä¸­å¼ï¼‰"""

    def __init__(self, state_dim=STATE_DIM, hidden_dim=HIDDEN_DIM,
                 action_dim=ACTION_DIM, num_heads=4):
        super().__init__()
        # ğŸ”§ ä½¿ç”¨ä¼ å…¥çš„ state_dimï¼ˆå³ global_state_dimï¼‰ï¼Œé¿å…â€œconfig å˜åŒ–ä½†è¿™é‡Œæ²¡è·Ÿä¸Šâ€
        self.critic = CentralizedCritic(state_dim, NUM_FOLLOWERS, action_dim, hidden_dim)

    def forward(self, global_state, joint_action):
        return self.critic(global_state, joint_action)


class ValueNetwork(nn.Module):
    """é›†ä¸­å¼ Value ç½‘ç»œåŒ…è£…å™¨ï¼ˆCTDE-MAPPO ç”¨ï¼‰ã€‚"""

    def __init__(self, state_dim=GLOBAL_STATE_DIM, hidden_dim=HIDDEN_DIM):
        super().__init__()
        self.value = CentralizedValue(state_dim, hidden_dim)

    def forward(self, global_state):
        return self.value(global_state)
