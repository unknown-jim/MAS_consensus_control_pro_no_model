"""ÈÖçÁΩÆÊñá‰ª∂ÔºàCTDE ÁâàÊú¨Ôºâ„ÄÇ

ËæìÂá∫ÁõÆÂΩïÁ∫¶ÂÆöÔºàÁªü‰∏ÄÁÆ°ÁêÜËÆ≠ÁªÉ‰∫ßÁâ©ÔºâÔºö
- Ê†πÁõÆÂΩïÔºöOUTPUT_ROOTÔºàÈªòËÆ§ results/Ôºâ
- ÊåâÁÆóÊ≥ï/Êó•ÊúüÂàÜÂ±ÇÔºöresults/<algo>/YYYYMMDD/HHMMSS/
- Ê®°ÂûãÔºö.../models/
- ÂõæÁâáÔºö.../figs/

ÂèØÈÄöËøáÁéØÂ¢ÉÂèòÈáèË¶ÜÁõñÔºö
- RUN_DIRÔºöÁõ¥Êé•ÊåáÂÆöÊú¨Ê¨°ËøêË°åËæìÂá∫ÁõÆÂΩïÔºàÊúÄÈ´ò‰ºòÂÖàÁ∫ßÔºâ
- OUTPUT_ROOTÔºöÊåáÂÆöÊ†πÁõÆÂΩïÔºàÈªòËÆ§ resultsÔºâ

Êú¨È°πÁõÆ‰∏çÂÜçÂåÖÂê´‰ªª‰Ωï‚ÄúÊóßÁâàÊú¨/ÊóßÊé•Âè£‚ÄùÁöÑÂÖºÂÆπÂàÜÊîØÔºö
- ËÆæÂ§áÈÄâÊã©‰ªÖÈááÁî®Ê†áÂáÜÁöÑ CUDA ÂèØÁî®ÊÄßÂà§ÂÆö
- ËÆ≠ÁªÉ/ÂèØËßÜÂåñ‰æùËµñÊåâ‚ÄúÂº∫‰æùËµñ‚ÄùÂ§ÑÁêÜÔºàÁº∫Â§±Áõ¥Êé•Êä•ÈîôÔºâ
"""

from __future__ import annotations

import os
import random
from datetime import datetime

import numpy as np
import torch

# ==================== ËÆæÂ§áÈÖçÁΩÆ ====================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==================== ÈöèÊú∫ÁßçÂ≠ê ====================
SEED = 42
TOPOLOGY_SEED = 42

# ==================== ËæìÂá∫ÁõÆÂΩïÔºàËÆ≠ÁªÉ/ËØÑ‰º∞‰∫ßÁâ©Áªü‰∏ÄËêΩÁõòÔºâ====================
OUTPUT_ROOT = os.getenv("OUTPUT_ROOT", "results")

_RUN_DATE = datetime.now().strftime("%Y%m%d")
_RUN_TIME = datetime.now().strftime("%H%M%S")

RUN_DIR = os.getenv("RUN_DIR", "").strip()
MODELS_DIR = ""
FIGS_DIR = ""


def ensure_dir(path: str) -> str:
    os.makedirs(path, exist_ok=True)
    return path


def ensure_parent_dir(file_path: str) -> str:
    parent = os.path.dirname(file_path)
    if parent:
        os.makedirs(parent, exist_ok=True)
    return file_path


# ==================== Ê®°ÂºèÈÄâÊã© ====================
LIGHTWEIGHT_MODE = True

# ==================== ÁÆóÊ≥ïÈÄâÊã© ====================
# ÂèØÈÄâÔºö"MASAC"ÔºàCTDE-SACÔºâ / "MAPPO"ÔºàCTDE-MAPPOÔºâ
ALGO = "MASAC"

# ==================== ËæìÂá∫ÁõÆÂΩïÔºàÊåâÁÆóÊ≥ïÈöîÁ¶ªÔºâ====================
_ALGO_TAG = str(ALGO).lower().strip() if str(ALGO).strip() else "unknown"
_RUN_DIR_DEFAULT = os.path.join(OUTPUT_ROOT, _ALGO_TAG, _RUN_DATE, _RUN_TIME)
if not RUN_DIR:
    RUN_DIR = _RUN_DIR_DEFAULT
MODELS_DIR = os.path.join(RUN_DIR, "models")
FIGS_DIR = os.path.join(RUN_DIR, "figs")

# ==================== ÁΩëÁªúÊãìÊâë ====================
NUM_FOLLOWERS = 14
NUM_PINNED = 3
NUM_AGENTS = NUM_FOLLOWERS + 1

# ==================== Êó†Ê®°ÂûãÁä∂ÊÄÅÁ©∫Èó¥ ====================
SELF_STATE_DIM = 2
SELF_LEADER_DIM = 4
LOCAL_OBS_DIM = SELF_STATE_DIM + SELF_LEADER_DIM  # 6

SELF_ROLE_DIM = 3

NEIGHBOR_STATE_DIM = 2
NEIGHBOR_LEADER_DIM = 4
NEIGHBOR_OBS_DIM = NEIGHBOR_STATE_DIM + NEIGHBOR_LEADER_DIM  # 6
NEIGHBOR_ROLE_DIM = 0

MAX_NEIGHBORS = 6
NEIGHBOR_FEAT_DIM = NEIGHBOR_OBS_DIM + NEIGHBOR_ROLE_DIM  # 6

STATE_DIM = LOCAL_OBS_DIM + SELF_ROLE_DIM + MAX_NEIGHBORS * NEIGHBOR_FEAT_DIM

# ==================== CTDE ÂÖ®Â±ÄÁä∂ÊÄÅÁª¥Â∫¶ ====================
GLOBAL_STATE_INCLUDE_BROADCAST = True
GLOBAL_STATE_INCLUDE_LEADER_PARAMS = True
GLOBAL_STATE_INCLUDE_TRAJ_TYPE = True
GLOBAL_STATE_INCLUDE_TIME = True

GLOBAL_STATE_DIM_BASE = NUM_AGENTS * 2
GLOBAL_STATE_DIM = GLOBAL_STATE_DIM_BASE

# ==================== Âä®‰ΩúÁ©∫Èó¥ ====================
ACTION_DIM = 2

# ==================== ÁéØÂ¢ÉÂèÇÊï∞ ====================
DT = 0.05
MAX_STEPS = 300

# ==================== È¢ÜÂØºËÄÖÂä®ÂäõÂ≠¶ÂèÇÊï∞ÔºàÂü∫ÂáÜÂÄºÔºâ====================
LEADER_AMPLITUDE = 2.0
LEADER_OMEGA = 0.5
LEADER_PHASE = 0.0

# ==================== ÈöèÊú∫ÂàùÂßãÂåñÂèÇÊï∞ ====================
RANDOMIZE_LEADER = True
RANDOMIZE_FOLLOWER = True
RANDOMIZE_TOPOLOGY = True

NUM_PINNED_RANGE = (2, 5)
EXTRA_EDGE_PROB = 0.15

LEADER_AMPLITUDE_RANGE = (1.0, 3.0)
LEADER_OMEGA_RANGE = (0.3, 0.8)
LEADER_PHASE_RANGE = (0.0, 2 * 3.14159)

LEADER_TRAJECTORY_TYPES = ["sine", "cosine"]

# finalize global state dim
if GLOBAL_STATE_INCLUDE_BROADCAST:
    GLOBAL_STATE_DIM += NUM_AGENTS * 2
if GLOBAL_STATE_INCLUDE_LEADER_PARAMS:
    GLOBAL_STATE_DIM += 3
if GLOBAL_STATE_INCLUDE_TRAJ_TYPE:
    GLOBAL_STATE_DIM += len(LEADER_TRAJECTORY_TYPES)
if GLOBAL_STATE_INCLUDE_TIME:
    GLOBAL_STATE_DIM += 1

FOLLOWER_INIT_POS_STD_RANGE = (0.4, 1.2)
FOLLOWER_INIT_VEL_STD_RANGE = (0.15, 0.5)

FOLLOWER_INIT_POS_STD = 0.5
FOLLOWER_INIT_VEL_STD = 0.2

POS_LIMIT = 10.0
VEL_LIMIT = 10.0

COMM_RANGE = 5.0

# ==================== ÈÄö‰ø°ÂèÇÊï∞ ====================
COMM_PENALTY = 0.15
THRESHOLD_MIN = 0.1
THRESHOLD_MAX = 1.0

# ==================== Â•ñÂä±ÂèÇÊï∞ ====================
TRACKING_PENALTY_SCALE = 2.0
TRACKING_PENALTY_MAX = 1.0
COMM_WEIGHT_DECAY = 0.8
IMPROVEMENT_SCALE = 1.5
IMPROVEMENT_CLIP = 0.3

REWARD_MIN = -2.0
REWARD_MAX = 2.0
USE_SOFT_REWARD_SCALING = True

# ==================== Dashboard ÊòæÁ§∫ÈòàÂÄº ====================
DASH_ERROR_GOOD_FRAC = 0.05
DASH_ERROR_POOR_FRAC = 0.20
DASH_COMM_GOOD_THRESHOLD = 0.30
DASH_COMM_POOR_THRESHOLD = 0.70

# ==================== ÁΩëÁªúÂèÇÊï∞ ====================
if LIGHTWEIGHT_MODE:
    HIDDEN_DIM = 192
    NUM_ATTENTION_HEADS = 4
    NUM_TRANSFORMER_LAYERS = 2
    DROPOUT = 0.05

    BATCH_SIZE = 256
    NUM_EPISODES = 1200
    NUM_PARALLEL_ENVS = 48

    UPDATE_FREQUENCY = 2
    GRADIENT_STEPS = 1
else:
    HIDDEN_DIM = 512
    NUM_ATTENTION_HEADS = 8
    NUM_TRANSFORMER_LAYERS = 3
    DROPOUT = 0.1

    BATCH_SIZE = 1024
    NUM_EPISODES = 2000
    NUM_PARALLEL_ENVS = 16

    UPDATE_FREQUENCY = 4
    GRADIENT_STEPS = 4

# ==================== SAC ÂèÇÊï∞ ====================
LEARNING_RATE = 3e-4
ACTOR_LR = 3e-4
CRITIC_LR = 3e-4
ALPHA_LR = 3e-4

# ==================== PPO/MAPPO ÂèÇÊï∞ ====================
PPO_LR = 3e-4
PPO_CLIP_EPS = 0.2
PPO_EPOCHS = 4
PPO_ROLLOUT_STEPS = 128
PPO_MINIBATCH_SIZE = 1024
PPO_GAE_LAMBDA = 0.95
PPO_VALUE_COEF = 0.5
PPO_ENTROPY_COEF = 0.01
PPO_MAX_GRAD_NORM = 1.0
PPO_TARGET_KL = 0.02

GAMMA = 0.99
TAU = 0.005

INIT_ALPHA = 0.2
AUTO_ALPHA = True
TARGET_ENTROPY_RATIO = 0.4

BUFFER_SIZE = 1_000_000

# ==================== Replay Buffer Â≠òÂÇ®ËÆæÁΩÆ ====================
REPLAY_BUFFER_DEVICE = torch.device("cpu") if DEVICE.type == "cuda" else DEVICE
REPLAY_BUFFER_DTYPE = torch.float16 if DEVICE.type == "cuda" else torch.float32
REPLAY_BUFFER_PIN_MEMORY = DEVICE.type == "cuda"

# ==================== Âä®‰ΩúÁº©Êîæ ====================
LOG_STD_MIN = -20
LOG_STD_MAX = 2
V_SCALE = 1.0
TH_SCALE = 1.0

# ==================== ËÆ≠ÁªÉÂèÇÊï∞ ====================
VIS_INTERVAL = 5
USE_AMP = True
WARMUP_STEPS = 3000

POLICY_DELAY = 2
TARGET_UPDATE_INTERVAL = 2

_SAVE_TAG = "mappo" if str(ALGO).upper().strip() == "MAPPO" else "masac"

SAVE_MODEL_PATH = os.path.join(
    MODELS_DIR,
    (f"best_model_ctde_14f_{_SAVE_TAG}_light.pt" if LIGHTWEIGHT_MODE else f"best_model_ctde_14f_{_SAVE_TAG}.pt"),
)

EVAL_NUM_TESTS = 3
EVAL_SAVE_PATH = os.path.join(FIGS_DIR, f"final_evaluation_ctde_{_SAVE_TAG}.png")

GENERALIZATION_TEST_STEPS = MAX_STEPS * 2
GENERALIZATION_SAVE_PATH = os.path.join(FIGS_DIR, f"generalization_test_ctde_{_SAVE_TAG}.png")

GENERALIZATION_INCLUDE_OOD = True
GENERALIZATION_OOD_AMPLITUDE = LEADER_AMPLITUDE
GENERALIZATION_OOD_OMEGA = LEADER_OMEGA_RANGE[1] * 1.25


def set_seed(seed: int = SEED) -> None:
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if DEVICE.type == "cuda":
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)


def print_config() -> None:
    mode_str = "Lightweight" if LIGHTWEIGHT_MODE else "Full"
    print("=" * 70)
    print(f"üîß Configuration - CTDE Architecture ({mode_str} Mode) - Large Scale")
    print(f"  Algorithm: {ALGO}")
    print("=" * 70)
    print(f"  Device: {DEVICE}")
    print(f"  Seed: {SEED}")
    print(f"  üåê Large-Scale MAS: {NUM_AGENTS} Agents (1 Leader + {NUM_FOLLOWERS} Followers)")
    print(f"  Episodes: {NUM_EPISODES}, Max Steps: {MAX_STEPS}")
    print(f"  üì° CTDE Settings:")
    print(f"     Local Obs Dim: {LOCAL_OBS_DIM} (self pos/vel + leader_est pos/vel + leader_seq/age)")
    print(f"     Self Role Dim: {SELF_ROLE_DIM} (one-hot: leader/pinned/normal)")
    print(f"     Neighbor Feat Dim: {NEIGHBOR_FEAT_DIM} (neighbor pos/vel + carried leader_est + leader_seq/age)")
    print(f"     Global State Dim: {GLOBAL_STATE_DIM}")
    print(f"       - include_broadcast: {GLOBAL_STATE_INCLUDE_BROADCAST}")
    print(f"       - include_leader_params: {GLOBAL_STATE_INCLUDE_LEADER_PARAMS}")
    print(f"       - include_traj_type: {GLOBAL_STATE_INCLUDE_TRAJ_TYPE}")
    print(f"       - include_time: {GLOBAL_STATE_INCLUDE_TIME}")
    print(f"     Max Neighbors: {MAX_NEIGHBORS}")
    print(f"     Actor Input: Local State ({STATE_DIM} = {LOCAL_OBS_DIM} + {SELF_ROLE_DIM} + {MAX_NEIGHBORS}√ó{NEIGHBOR_FEAT_DIM})")
    print(f"     Critic Input: Global State ({GLOBAL_STATE_DIM}) + Joint Action ({NUM_FOLLOWERS * ACTION_DIM})")
    print(f"  üé≠ Role Encoding:")
    print(f"     [1,0,0] = Leader")
    print(f"     [0,1,0] = Pinned Follower (direct leader connection)")
    print(f"     [0,0,1] = Normal Follower")
    print(f"  üé≤ Randomization Settings:")
    print(f"     Randomize Leader: {RANDOMIZE_LEADER}")
    if RANDOMIZE_LEADER:
        print(f"       Amplitude: {LEADER_AMPLITUDE_RANGE}")
        print(f"       Omega: {LEADER_OMEGA_RANGE}")
        print(f"       Phase: {LEADER_PHASE_RANGE}")
    print(f"     Randomize Follower: {RANDOMIZE_FOLLOWER}")
    if RANDOMIZE_FOLLOWER:
        print(f"       Pos Std: {FOLLOWER_INIT_POS_STD_RANGE}")
        print(f"       Vel Std: {FOLLOWER_INIT_VEL_STD_RANGE}")
    print(f"     Randomize Topology: {RANDOMIZE_TOPOLOGY}")
    if RANDOMIZE_TOPOLOGY:
        print(f"       Pinned Range: {NUM_PINNED_RANGE}")
        print(f"       Extra Edge Prob: {EXTRA_EDGE_PROB}")
    print(f"  üß† Network Settings ({mode_str} - Scaled for {NUM_FOLLOWERS} followers):")
    print(f"     Hidden Dim: {HIDDEN_DIM}")
    print(f"     Attention Heads: {NUM_ATTENTION_HEADS}")
    print(f"     Transformer Layers: {NUM_TRANSFORMER_LAYERS}")
    print(f"     Dropout: {DROPOUT}")
    print(f"  ‚ö° Training Settings:")
    print(f"     Batch Size: {BATCH_SIZE}")
    print(f"     Parallel Envs: {NUM_PARALLEL_ENVS}")
    print(f"     Update Frequency: {UPDATE_FREQUENCY}")
    print(f"     Gradient Steps: {GRADIENT_STEPS}")
    print(f"     Policy Delay: {POLICY_DELAY}")
    print(f"     Target Update Interval: {TARGET_UPDATE_INTERVAL}")
    print(f"     Buffer Size: {BUFFER_SIZE:,}")
    print(f"     Replay Buffer Device: {REPLAY_BUFFER_DEVICE}")
    print(f"     Replay Buffer DType: {REPLAY_BUFFER_DTYPE}")
    print(f"     Replay Buffer Pin Memory: {REPLAY_BUFFER_PIN_MEMORY}")
    print(f"  üì° Communication Settings:")
    print(f"     Base Comm Penalty: {COMM_PENALTY}")
    print(f"     Comm Weight Decay: {COMM_WEIGHT_DECAY}")
    print(f"     Threshold Range: [{THRESHOLD_MIN}, {THRESHOLD_MAX}]")
    print(f"  üíæ Output Paths:")
    print(f"     RUN_DIR: {RUN_DIR}")
    print(f"     MODELS_DIR: {MODELS_DIR}")
    print(f"     FIGS_DIR: {FIGS_DIR}")
    print(f"     SAVE_MODEL_PATH: {SAVE_MODEL_PATH}")
    print(f"     EVAL_SAVE_PATH: {EVAL_SAVE_PATH}")
    print(f"  üéØ Reward Settings (Soft Comm Reduction):")
    print(f"     Tracking Penalty: -{TRACKING_PENALTY_MAX}*log1p(err_norm*{TRACKING_PENALTY_SCALE})")
    print(f"       where err_norm = mean(|pos_f-leader|)/{POS_LIMIT} + 0.5*mean(|vel_f-leader|)/{VEL_LIMIT}")
    print(f"     Comm Penalty: {COMM_PENALTY}")
    print(f"     Comm Weight Decay: {COMM_WEIGHT_DECAY}")
    print(f"     Improvement: scale={IMPROVEMENT_SCALE}, clip=¬±{IMPROVEMENT_CLIP}")
    print(f"  üîß Action Scales: V={V_SCALE}, TH={TH_SCALE}")
    print(f"  üî• Warmup Steps: {WARMUP_STEPS}")
    if RANDOMIZE_LEADER:
        print(f"  üé≠ Leader Trajectory Types: {LEADER_TRAJECTORY_TYPES}")
    print("=" * 70)
