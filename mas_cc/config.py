"""é…ç½®æ–‡ä»¶ï¼ˆCTDE ç‰ˆæœ¬ï¼‰ã€‚

è¾“å‡ºç›®å½•çº¦å®šï¼ˆç»Ÿä¸€ç®¡ç†è®­ç»ƒäº§ç‰©ï¼‰ï¼š
- æ ¹ç›®å½•ï¼šOUTPUT_ROOTï¼ˆé»˜è®¤ results/ï¼‰
- æŒ‰ç®—æ³•/æ—¥æœŸåˆ†å±‚ï¼šresults/<algo>/YYYYMMDD/HHMMSS/
- æ¨¡å‹ï¼š.../models/
- å›¾ç‰‡ï¼š.../figs/

å¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼š
- RUN_DIRï¼šç›´æ¥æŒ‡å®šæœ¬æ¬¡è¿è¡Œè¾“å‡ºç›®å½•ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
- OUTPUT_ROOTï¼šæŒ‡å®šæ ¹ç›®å½•ï¼ˆé»˜è®¤ resultsï¼‰

æœ¬é¡¹ç›®ä¸å†åŒ…å«ä»»ä½•â€œæ—§ç‰ˆæœ¬/æ—§æ¥å£â€çš„å…¼å®¹åˆ†æ”¯ï¼š
- è®¾å¤‡é€‰æ‹©ä»…é‡‡ç”¨æ ‡å‡†çš„ CUDA å¯ç”¨æ€§åˆ¤å®š
- è®­ç»ƒ/å¯è§†åŒ–ä¾èµ–æŒ‰â€œå¼ºä¾èµ–â€å¤„ç†ï¼ˆç¼ºå¤±ç›´æ¥æŠ¥é”™ï¼‰
"""

from __future__ import annotations

import os
import random
from datetime import datetime

import numpy as np
import torch

# ==================== è®¾å¤‡é…ç½® ====================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==================== éšæœºç§å­ ====================
SEED = 42
TOPOLOGY_SEED = 42

# ==================== è¾“å‡ºç›®å½•ï¼ˆè®­ç»ƒ/è¯„ä¼°äº§ç‰©ç»Ÿä¸€è½ç›˜ï¼‰====================
OUTPUT_ROOT = os.getenv("OUTPUT_ROOT", "results")

_RUN_DATE = datetime.now().strftime("%Y%m%d")
_RUN_TIME = datetime.now().strftime("%H%M%S")

RUN_DIR = os.getenv("RUN_DIR", "").strip()
MODELS_DIR = ""
FIGS_DIR = ""


def ensure_dir(path: str) -> str:
    """ç¡®ä¿ç›®å½•å­˜åœ¨ã€‚

    Args:
        path: ç›®å½•è·¯å¾„ã€‚

    Returns:
        åŸæ ·è¿”å› `path`ï¼Œä¾¿äºåœ¨é…ç½®ä¸­é“¾å¼ä½¿ç”¨ã€‚
    """
    os.makedirs(path, exist_ok=True)
    return path


def ensure_parent_dir(file_path: str) -> str:
    """ç¡®ä¿æ–‡ä»¶çš„çˆ¶ç›®å½•å­˜åœ¨ã€‚

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ã€‚

    Returns:
        åŸæ ·è¿”å› `file_path`ã€‚
    """
    parent = os.path.dirname(file_path)
    if parent:
        os.makedirs(parent, exist_ok=True)
    return file_path


# ==================== æ¨¡å¼é€‰æ‹© ====================
LIGHTWEIGHT_MODE = True

# ==================== ç®—æ³•é€‰æ‹© ====================
# å¯é€‰ï¼š"MASAC"ï¼ˆCTDE-SACï¼‰ / "MAPPO"ï¼ˆCTDE-MAPPOï¼‰
ALGO = "MAPPO"

# ==================== è¾“å‡ºç›®å½•ï¼ˆæŒ‰ç®—æ³•éš”ç¦»ï¼‰====================
_ALGO_TAG = str(ALGO).lower().strip() if str(ALGO).strip() else "unknown"
_RUN_DIR_DEFAULT = os.path.join(OUTPUT_ROOT, _ALGO_TAG, _RUN_DATE, _RUN_TIME)
if not RUN_DIR:
    RUN_DIR = _RUN_DIR_DEFAULT
MODELS_DIR = os.path.join(RUN_DIR, "models")
FIGS_DIR = os.path.join(RUN_DIR, "figs")

# ==================== ç½‘ç»œæ‹“æ‰‘ ====================
NUM_FOLLOWERS = 20
NUM_PINNED = 5
NUM_AGENTS = NUM_FOLLOWERS + 1

# ==================== æ— æ¨¡å‹çŠ¶æ€ç©ºé—´ ====================
SELF_STATE_DIM = 2
SELF_LEADER_DIM = 4
LOCAL_OBS_DIM = SELF_STATE_DIM + SELF_LEADER_DIM  # 6

SELF_ROLE_DIM = 3

NEIGHBOR_STATE_DIM = 2
NEIGHBOR_LEADER_DIM = 4
NEIGHBOR_OBS_DIM = NEIGHBOR_STATE_DIM + NEIGHBOR_LEADER_DIM  # 6
NEIGHBOR_ROLE_DIM = 0

# Actor è§‚æµ‹é‡Œçš„ Top-K é‚»å±…æ§½ä½æ•°ï¼ˆå›ºå®šç»´åº¦ï¼Œä¸éšæ™ºèƒ½ä½“æ•°é‡å¢é•¿ï¼‰
#
# å¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼ˆåœ¨å¯¼å…¥æœ¬æ¨¡å—å‰è®¾ç½®ï¼‰ï¼š
# - MAX_NEIGHBORS=12 python train.py
# - TOP_K=12 python train.py  ï¼ˆå…¼å®¹åˆ«åï¼‰
_MAX_NEIGHBORS_DEFAULT = 4
_max_neighbors_env = os.getenv("MAX_NEIGHBORS", "").strip() or os.getenv("TOP_K", "").strip()
MAX_NEIGHBORS = int(_max_neighbors_env) if _max_neighbors_env else int(_MAX_NEIGHBORS_DEFAULT)
if MAX_NEIGHBORS <= 0:
    raise ValueError(f"MAX_NEIGHBORS must be positive, got {MAX_NEIGHBORS}")

NEIGHBOR_FEAT_DIM = NEIGHBOR_OBS_DIM + NEIGHBOR_ROLE_DIM  # 6

STATE_DIM = LOCAL_OBS_DIM + SELF_ROLE_DIM + MAX_NEIGHBORS * NEIGHBOR_FEAT_DIM

# ==================== CTDE å…¨å±€çŠ¶æ€ç»´åº¦ ====================
GLOBAL_STATE_INCLUDE_BROADCAST = True
GLOBAL_STATE_INCLUDE_LEADER_PARAMS = True
GLOBAL_STATE_INCLUDE_TRAJ_TYPE = True
GLOBAL_STATE_INCLUDE_TIME = True

GLOBAL_STATE_DIM_BASE = NUM_AGENTS * 2
GLOBAL_STATE_DIM = GLOBAL_STATE_DIM_BASE

# ==================== åŠ¨ä½œç©ºé—´ ====================
ACTION_DIM = 2

# ==================== ç¯å¢ƒå‚æ•° ====================
DT = 0.05
MAX_STEPS = 300

# ==================== é¢†å¯¼è€…åŠ¨åŠ›å­¦å‚æ•°ï¼ˆåŸºå‡†å€¼ï¼‰====================
LEADER_AMPLITUDE = 2.0
LEADER_OMEGA = 0.5
LEADER_PHASE = 0.0

# ==================== éšæœºåˆå§‹åŒ–å‚æ•° ====================
RANDOMIZE_LEADER = True
RANDOMIZE_FOLLOWER = True
RANDOMIZE_TOPOLOGY = True

NUM_PINNED_RANGE = (2, 5)
EXTRA_EDGE_PROB = 0.15

LEADER_AMPLITUDE_RANGE = (1.0, 3.0)
LEADER_OMEGA_RANGE = (0.3, 0.8)
LEADER_PHASE_RANGE = (0.0, 2 * 3.14159)

LEADER_TRAJECTORY_TYPES = ["sine", "cosine"]

# finalize global state dim
if GLOBAL_STATE_INCLUDE_BROADCAST:
    GLOBAL_STATE_DIM += NUM_AGENTS * 2
if GLOBAL_STATE_INCLUDE_LEADER_PARAMS:
    GLOBAL_STATE_DIM += 3
if GLOBAL_STATE_INCLUDE_TRAJ_TYPE:
    GLOBAL_STATE_DIM += len(LEADER_TRAJECTORY_TYPES)
if GLOBAL_STATE_INCLUDE_TIME:
    GLOBAL_STATE_DIM += 1

FOLLOWER_INIT_POS_STD_RANGE = (0.4, 1.2)
FOLLOWER_INIT_VEL_STD_RANGE = (0.15, 0.5)

FOLLOWER_INIT_POS_STD = 0.5
FOLLOWER_INIT_VEL_STD = 0.2

POS_LIMIT = 10.0
VEL_LIMIT = 10.0

COMM_RANGE = 5.0

# ==================== é€šä¿¡å‚æ•° ====================
# äº‹ä»¶è§¦å‘é˜ˆå€¼èŒƒå›´ï¼šå½“ |pos - last_broadcast_pos| > threshold æ—¶è§¦å‘é€šä¿¡
# æ³¨æ„ï¼šæ¯æ­¥æœ€å¤§ä½ç½®å˜åŒ– = VEL_LIMIT Ã— DT = 0.5
# é˜ˆå€¼åº”è¯¥ < 0.5 æ‰èƒ½æœ‰æ•ˆè§¦å‘é€šä¿¡
COMM_PENALTY = 0.15  # é€šä¿¡æƒ©ç½šï¼ˆå¢å¤§ä»¥é¼“åŠ±èŠ‚çœé€šä¿¡ï¼‰
THRESHOLD_MIN = 0.05  # æœ€å°é˜ˆå€¼ï¼ˆé«˜é€šä¿¡ç‡ï¼‰- æé«˜ä¸‹é™ï¼Œé¿å…è¿‡äºæ•æ„Ÿ
THRESHOLD_MAX = 0.5   # æœ€å¤§é˜ˆå€¼ï¼ˆä½é€šä¿¡ç‡ï¼‰- æé«˜ä¸Šé™ï¼Œå…è®¸æ›´ä½é€šä¿¡ç‡

# ==================== ç¡®å®šæ€§äº‹ä»¶è§¦å‘ï¼ˆETCï¼‰å‚æ•° ====================
# è§¦å‘æ¡ä»¶ï¼šdelta = |x - x_b| + ETC_VEL_COEF * DT * |v - v_b| > theta
ETC_VEL_COEF = 0.5  # é€Ÿåº¦å¢é‡æ˜ å°„ç³»æ•°ï¼ˆé™ä½ï¼Œå‡å°‘é€Ÿåº¦å¯¹ delta çš„è´¡çŒ®ï¼‰

# æ–°é²œåº¦ä¿åº•è§¦å‘ï¼šå½“ leader_age > AGE_MAX_STEPS æ—¶å¼ºåˆ¶è§¦å‘ï¼ˆå³ä¾¿ delta <= thetaï¼‰
# è¿™å¯¹"ä½è¯¯å·®"ç›®æ ‡éå¸¸å…³é”®ï¼šé˜²æ­¢ gossip é“¾è·¯ä¸ç•…æ—¶ leader ä¼°è®¡è¿‡æ—§
AGE_MAX_STEPS = 10  # æ”¾å®½ä¿åº•è§¦å‘ï¼ˆåŸ5å¤ªç´§ï¼Œé™åˆ¶äº†ç­–ç•¥æ¢ç´¢ç©ºé—´ï¼‰

# å»æŠ–/æœ€å°è§¦å‘é—´éš”ï¼šè§¦å‘å COOLDOWN_STEPS æ­¥å†…ä¸å†è§¦å‘
# é˜²æ­¢é˜ˆå€¼è¾¹ç•Œæ¥å›è·¨è¶Šå¯¼è‡´é¢‘ç¹å¼€å…³
COOLDOWN_STEPS = 1  # é™ä½ cooldownï¼ˆåŸ2å¤ªç´§ï¼Œé”æ­»é€šä¿¡ç‡ä¸Šé™åœ¨33%ï¼‰

# ==================== å¥–åŠ±å‚æ•° ====================
TRACKING_PENALTY_SCALE = 2.0
TRACKING_PENALTY_MAX = 1.0
COMM_WEIGHT_DECAY = 0.8  # é™ä½è¡°å‡ï¼ˆåŸ1.5å¤ªå¤§ï¼‰ï¼Œè®©é€šä¿¡æƒ©ç½šåœ¨ä½è¯¯å·®æ—¶æ›´æ˜¾è‘—
IMPROVEMENT_SCALE = 1.5
IMPROVEMENT_CLIP = 0.3
INFO_GAIN_SCALE = 0.3  # ä¿¡æ¯å¢ç›Šå¥–åŠ±ç³»æ•°ï¼ˆé™ä½ï¼Œé¿å…è¿‡åº¦é¼“åŠ±é€šä¿¡ï¼‰

REWARD_MIN = -2.0
REWARD_MAX = 2.0
USE_SOFT_REWARD_SCALING = True

# ==================== Dashboard æ˜¾ç¤ºé˜ˆå€¼ ====================
DASH_ERROR_GOOD_FRAC = 0.05
DASH_ERROR_POOR_FRAC = 0.20
DASH_COMM_GOOD_THRESHOLD = 0.30
DASH_COMM_POOR_THRESHOLD = 0.70

# ==================== ç½‘ç»œå‚æ•° ====================
if LIGHTWEIGHT_MODE:
    HIDDEN_DIM = 192
    NUM_ATTENTION_HEADS = 4
    NUM_TRANSFORMER_LAYERS = 2
    DROPOUT = 0.05

    BATCH_SIZE = 256
    NUM_EPISODES = 1200
    NUM_PARALLEL_ENVS = 48

    UPDATE_FREQUENCY = 2
    GRADIENT_STEPS = 1
else:
    HIDDEN_DIM = 512
    NUM_ATTENTION_HEADS = 8
    NUM_TRANSFORMER_LAYERS = 3
    DROPOUT = 0.1

    BATCH_SIZE = 1024
    NUM_EPISODES = 2000
    NUM_PARALLEL_ENVS = 16

    UPDATE_FREQUENCY = 4
    GRADIENT_STEPS = 4

# ==================== SAC å‚æ•° ====================
LEARNING_RATE = 3e-4
ACTOR_LR = 3e-4
CRITIC_LR = 3e-4
ALPHA_LR = 3e-4

# ==================== PPO/MAPPO å‚æ•° ====================
PPO_LR = 1e-4  # é™ä½å­¦ä¹ ç‡ï¼ˆåŸ 3e-4ï¼‰ï¼Œæé«˜ç¨³å®šæ€§
PPO_CLIP_EPS = 0.15  # å‡å°è£å‰ªèŒƒå›´ï¼ˆåŸ 0.2ï¼‰ï¼Œé™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦
PPO_EPOCHS = 4
PPO_ROLLOUT_STEPS = 128
PPO_MINIBATCH_SIZE = 1024
PPO_GAE_LAMBDA = 0.95
PPO_VALUE_COEF = 0.5
PPO_ENTROPY_COEF = 0.05  # å¤§å¹…å¢åŠ ç†µç³»æ•°ï¼Œé˜²æ­¢ Beta åˆ†å¸ƒç†µå´©æºƒ
PPO_MAX_GRAD_NORM = 0.5  # å‡å°æ¢¯åº¦è£å‰ªï¼ˆåŸ 1.0ï¼‰ï¼Œæé«˜ç¨³å®šæ€§
PPO_TARGET_KL = 0.015  # å‡å°ç›®æ ‡ KLï¼ˆåŸ 0.02ï¼‰ï¼Œæ›´ä¿å®ˆçš„æ›´æ–°

GAMMA = 0.99
TAU = 0.005

INIT_ALPHA = 0.2
AUTO_ALPHA = True
TARGET_ENTROPY_RATIO = 0.4

BUFFER_SIZE = 1_000_000

# ==================== Replay Buffer å­˜å‚¨è®¾ç½® ====================
REPLAY_BUFFER_DEVICE = torch.device("cpu") if DEVICE.type == "cuda" else DEVICE
REPLAY_BUFFER_DTYPE = torch.float16 if DEVICE.type == "cuda" else torch.float32
REPLAY_BUFFER_PIN_MEMORY = DEVICE.type == "cuda"

# ==================== åŠ¨ä½œç¼©æ”¾ ====================
LOG_STD_MIN = -20
LOG_STD_MAX = 2
V_SCALE = 1.0
TH_SCALE = 1.0

# ==================== è®­ç»ƒå‚æ•° ====================
VIS_INTERVAL = 10
USE_AMP = True
WARMUP_STEPS = 3000

POLICY_DELAY = 2
TARGET_UPDATE_INTERVAL = 2

_SAVE_TAG = "mappo" if str(ALGO).upper().strip() == "MAPPO" else "masac"

SAVE_MODEL_PATH = os.path.join(
    MODELS_DIR,
    (f"best_model_ctde_14f_{_SAVE_TAG}_light.pt" if LIGHTWEIGHT_MODE else f"best_model_ctde_14f_{_SAVE_TAG}.pt"),
)

EVAL_NUM_TESTS = 3
EVAL_SAVE_PATH = os.path.join(FIGS_DIR, f"final_evaluation_ctde_{_SAVE_TAG}.png")

GENERALIZATION_TEST_STEPS = MAX_STEPS * 2
GENERALIZATION_SAVE_PATH = os.path.join(FIGS_DIR, f"generalization_test_ctde_{_SAVE_TAG}.png")

GENERALIZATION_INCLUDE_OOD = True
GENERALIZATION_OOD_AMPLITUDE = LEADER_AMPLITUDE
GENERALIZATION_OOD_OMEGA = LEADER_OMEGA_RANGE[1] * 1.25


def set_seed(seed: int = SEED) -> None:
    """è®¾ç½®éšæœºç§å­ã€‚

    Args:
        seed: éšæœºç§å­ã€‚

    Notes:
        è‹¥å½“å‰è®¾å¤‡ä¸º CUDAï¼Œä¼šé¢å¤–è®¾ç½® `torch.cuda.manual_seed(_all)`ã€‚
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if DEVICE.type == "cuda":
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)


def print_config() -> None:
    """æ‰“å°å½“å‰å…³é”®é…ç½®ï¼ˆç”¨äºå®éªŒå¯å¤ç°ä¸æ’æŸ¥ï¼‰ã€‚"""
    mode_str = "Lightweight" if LIGHTWEIGHT_MODE else "Full"
    print("=" * 70)
    print(f"ğŸ”§ Configuration - CTDE Architecture ({mode_str} Mode) - Large Scale")
    print(f"  Algorithm: {ALGO}")
    print("=" * 70)
    print(f"  Device: {DEVICE}")
    print(f"  Seed: {SEED}")
    print(f"  ğŸŒ Large-Scale MAS: {NUM_AGENTS} Agents (1 Leader + {NUM_FOLLOWERS} Followers)")
    print(f"  Episodes: {NUM_EPISODES}, Max Steps: {MAX_STEPS}")
    print(f"  ğŸ“¡ CTDE Settings:")
    print(f"     Local Obs Dim: {LOCAL_OBS_DIM} (self pos/vel + leader_est pos/vel + leader_seq/age)")
    print(f"     Self Role Dim: {SELF_ROLE_DIM} (one-hot: leader/pinned/normal)")
    print(f"     Neighbor Feat Dim: {NEIGHBOR_FEAT_DIM} (neighbor pos/vel + carried leader_est + leader_seq/age)")
    print(f"     Global State Dim: {GLOBAL_STATE_DIM}")
    print(f"       - include_broadcast: {GLOBAL_STATE_INCLUDE_BROADCAST}")
    print(f"       - include_leader_params: {GLOBAL_STATE_INCLUDE_LEADER_PARAMS}")
    print(f"       - include_traj_type: {GLOBAL_STATE_INCLUDE_TRAJ_TYPE}")
    print(f"       - include_time: {GLOBAL_STATE_INCLUDE_TIME}")
    print(f"     Max Neighbors: {MAX_NEIGHBORS}")
    print(f"     Actor Input: Local State ({STATE_DIM} = {LOCAL_OBS_DIM} + {SELF_ROLE_DIM} + {MAX_NEIGHBORS}Ã—{NEIGHBOR_FEAT_DIM})")
    print(f"     Critic Input: Global State ({GLOBAL_STATE_DIM}) + Joint Action ({NUM_FOLLOWERS * ACTION_DIM})")
    print(f"  ğŸ­ Role Encoding:")
    print(f"     [1,0,0] = Leader")
    print(f"     [0,1,0] = Pinned Follower (direct leader connection)")
    print(f"     [0,0,1] = Normal Follower")
    print(f"  ğŸ² Randomization Settings:")
    print(f"     Randomize Leader: {RANDOMIZE_LEADER}")
    if RANDOMIZE_LEADER:
        print(f"       Amplitude: {LEADER_AMPLITUDE_RANGE}")
        print(f"       Omega: {LEADER_OMEGA_RANGE}")
        print(f"       Phase: {LEADER_PHASE_RANGE}")
    print(f"     Randomize Follower: {RANDOMIZE_FOLLOWER}")
    if RANDOMIZE_FOLLOWER:
        print(f"       Pos Std: {FOLLOWER_INIT_POS_STD_RANGE}")
        print(f"       Vel Std: {FOLLOWER_INIT_VEL_STD_RANGE}")
    print(f"     Randomize Topology: {RANDOMIZE_TOPOLOGY}")
    if RANDOMIZE_TOPOLOGY:
        print(f"       Pinned Range: {NUM_PINNED_RANGE}")
        print(f"       Extra Edge Prob: {EXTRA_EDGE_PROB}")
    print(f"  ğŸ§  Network Settings ({mode_str} - Scaled for {NUM_FOLLOWERS} followers):")
    print(f"     Hidden Dim: {HIDDEN_DIM}")
    print(f"     Attention Heads: {NUM_ATTENTION_HEADS}")
    print(f"     Transformer Layers: {NUM_TRANSFORMER_LAYERS}")
    print(f"     Dropout: {DROPOUT}")
    print(f"  âš¡ Training Settings:")
    print(f"     Batch Size: {BATCH_SIZE}")
    print(f"     Parallel Envs: {NUM_PARALLEL_ENVS}")
    print(f"     Update Frequency: {UPDATE_FREQUENCY}")
    print(f"     Gradient Steps: {GRADIENT_STEPS}")
    print(f"     Policy Delay: {POLICY_DELAY}")
    print(f"     Target Update Interval: {TARGET_UPDATE_INTERVAL}")
    print(f"     Buffer Size: {BUFFER_SIZE:,}")
    print(f"     Replay Buffer Device: {REPLAY_BUFFER_DEVICE}")
    print(f"     Replay Buffer DType: {REPLAY_BUFFER_DTYPE}")
    print(f"     Replay Buffer Pin Memory: {REPLAY_BUFFER_PIN_MEMORY}")
    print(f"  ğŸ“¡ Communication Settings:")
    print(f"     Base Comm Penalty: {COMM_PENALTY}")
    print(f"     Comm Weight Decay: {COMM_WEIGHT_DECAY}")
    print(f"     Threshold Range: [{THRESHOLD_MIN}, {THRESHOLD_MAX}]")
    print(f"  ğŸ’¾ Output Paths:")
    print(f"     RUN_DIR: {RUN_DIR}")
    print(f"     MODELS_DIR: {MODELS_DIR}")
    print(f"     FIGS_DIR: {FIGS_DIR}")
    print(f"     SAVE_MODEL_PATH: {SAVE_MODEL_PATH}")
    print(f"     EVAL_SAVE_PATH: {EVAL_SAVE_PATH}")
    print(f"  ğŸ¯ Reward Settings (Soft Comm Reduction):")
    print(f"     Tracking Penalty: -{TRACKING_PENALTY_MAX}*log1p(err_norm*{TRACKING_PENALTY_SCALE})")
    print(f"       where err_norm = mean(|pos_f-leader|)/{POS_LIMIT} + 0.01*mean(|vel_f-leader|)/{VEL_LIMIT}")
    print(f"     Comm Penalty: {COMM_PENALTY}")
    print(f"     Comm Weight Decay: {COMM_WEIGHT_DECAY}")
    print(f"     Improvement: scale={IMPROVEMENT_SCALE}, clip=Â±{IMPROVEMENT_CLIP}")
    print(f"  ğŸ”§ Action Scales: V={V_SCALE}, TH={TH_SCALE}")
    print(f"  ğŸ”¥ Warmup Steps: {WARMUP_STEPS}")
    if RANDOMIZE_LEADER:
        print(f"  ğŸ­ Leader Trajectory Types: {LEADER_TRAJECTORY_TYPES}")
    print("=" * 70)
