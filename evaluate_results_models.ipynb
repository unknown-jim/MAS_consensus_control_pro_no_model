{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "542e7e17",
      "metadata": {},
      "source": [
        "# ğŸ§ª Evaluate Models in `results/`\n",
        "\n",
        "è¿™ä¸ª Notebook ç”¨äºè¯„ä¼°/å¯è§†åŒ–ä½ åœ¨ `results/` ä¸‹è®­ç»ƒå‡ºçš„æ¨¡å‹ï¼š\n",
        "- **æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹è·¯å¾„**ï¼šç›´æ¥å¡« `MODEL_PATH`ï¼ˆç»å¯¹/ç›¸å¯¹è·¯å¾„éƒ½å¯ï¼‰ã€‚\n",
        "- **æŒ‰ç®—æ³•è‡ªåŠ¨åŠ è½½æœ€æ–°æ¨¡å‹**ï¼šåªé€‰ `ALGO_TAG`ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨å¯»æ‰¾è¯¥ç®—æ³•çš„æœ€æ–° `best_model*.pt`ã€‚\n",
        "\n",
        "è‡ªåŠ¨æœç´¢ä¼šå…¼å®¹ä¸‰ç§ä½ç½®ï¼š\n",
        "1) æ–°ç»“æ„ï¼š`results/<algo>/**/models/`\n",
        "2) æ—§ç»“æ„ï¼š`results/**/models/`ï¼ˆä¼šè·³è¿‡ `results/eval/`ï¼‰\n",
        "3) æ›´æ—§ï¼šé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ `best_model*.pt`\n",
        "\n",
        "è¯„ä¼°äº§ç‰©ï¼ˆæŒ‡æ ‡ JSONã€å›¾åƒï¼‰**é»˜è®¤ä¸ä¿å­˜**ï¼›å¦‚éœ€è½ç›˜ï¼Œå¯åœ¨ç¬¬ 3 æ­¥æŠŠ `SAVE_OUTPUTS=True`ï¼Œä¿å­˜åˆ°ï¼š`results/eval/<algo>/YYYYMMDD/HHMMSS/`ï¼ˆä¸è®­ç»ƒäº§ç‰©åˆ†å¼€ï¼‰ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425bcb8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "\n",
        "# é¡¹ç›®æ¨¡å—\n",
        "from config import (\n",
        "    DEVICE, SEED, set_seed,\n",
        "    NUM_FOLLOWERS, NUM_PINNED, MAX_STEPS,\n",
        ")\n",
        "from topology import CommunicationTopology\n",
        "from environment import ModelFreeEnv\n",
        "from agent import CTDESACAgent, CTDEMAPPOAgent\n",
        "from utils import evaluate_agent, plot_evaluation\n",
        "\n",
        "print('DEVICE:', DEVICE)\n",
        "print('torch:', torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecec9563",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _algo_tag_normalize(tag: str) -> str:\n",
        "    tag = (tag or '').strip().lower()\n",
        "    if tag in ('masac', 'sac', 'ctdesac', 'ctde_sac'):\n",
        "        return 'masac'\n",
        "    if tag in ('mappo', 'ppo', 'ctdemappo', 'ctde_mappo'):\n",
        "        return 'mappo'\n",
        "    return tag or 'masac'\n",
        "\n",
        "\n",
        "def find_latest_model_in_results(algo_tag: str, results_root: str | Path = 'results', pattern: str = 'best_model*.pt') -> str:\n",
        "    \"\"\"æŒ‰ä¿®æ”¹æ—¶é—´æ‰¾â€œæœ€æ–°æ¨¡å‹â€ã€‚æœç´¢é¡ºåºï¼š\n",
        "    1) results/<algo>/**/models/<pattern>\n",
        "    2) å…¼å®¹æ—§ç»“æ„ï¼šresults/**/models/<pattern>ï¼ˆè‡ªåŠ¨è·³è¿‡ results/evalï¼‰\n",
        "    3) å…¼å®¹æ›´æ—§ï¼šé¡¹ç›®æ ¹ç›®å½• ./best_model*.pt\n",
        "    \"\"\"\n",
        "    algo_tag = _algo_tag_normalize(algo_tag)\n",
        "    results_root = Path(results_root)\n",
        "\n",
        "    def _is_algo_match(p: Path) -> bool:\n",
        "        n = p.name.lower()\n",
        "        if algo_tag == 'mappo':\n",
        "            return ('mappo' in n) or ('ppo' in n and 'masac' not in n)\n",
        "        if algo_tag == 'masac':\n",
        "            # å…è®¸ generic best_model.ptï¼›åŒæ—¶æ’é™¤ mappo/ppo\n",
        "            return ('masac' in n) or (('mappo' not in n) and ('ppo' not in n))\n",
        "        return True\n",
        "\n",
        "    def _collect_from_dir(base: Path) -> list[Path]:\n",
        "        out: list[Path] = []\n",
        "        if not base.exists():\n",
        "            return out\n",
        "        for p in base.rglob(pattern):\n",
        "            if not (p.is_file() and p.parent.name == 'models'):\n",
        "                continue\n",
        "            # è·³è¿‡ eval ç›®å½•\n",
        "            if 'eval' in p.parts:\n",
        "                continue\n",
        "            if _is_algo_match(p):\n",
        "                out.append(p)\n",
        "        return out\n",
        "\n",
        "    candidates: list[Path] = []\n",
        "\n",
        "    # 1) æ–°ç»“æ„ï¼šresults/<algo>/...\n",
        "    candidates += _collect_from_dir(results_root / algo_tag)\n",
        "\n",
        "    # 2) æ—§ç»“æ„ï¼šresults/YYYYMMDD/HHMMSS/models/...\n",
        "    if not candidates:\n",
        "        candidates += _collect_from_dir(results_root)\n",
        "\n",
        "    # 3) æ›´æ—§ï¼šé¡¹ç›®æ ¹ç›®å½•\n",
        "    if not candidates:\n",
        "        for p in Path('.').glob(pattern):\n",
        "            if p.is_file() and _is_algo_match(p):\n",
        "                candidates.append(p)\n",
        "\n",
        "    if not candidates:\n",
        "        raise FileNotFoundError(\n",
        "            f\"æœªæ‰¾åˆ°æ¨¡å‹ï¼šalgo={algo_tag}, pattern={pattern}ã€‚\\n\"\n",
        "            f\"å·²æœç´¢ï¼š{results_root / algo_tag}ã€{results_root}ï¼ˆè·³è¿‡ evalï¼‰ã€ä»¥åŠé¡¹ç›®æ ¹ç›®å½•ã€‚\"\n",
        "        )\n",
        "\n",
        "    latest = max(candidates, key=lambda x: x.stat().st_mtime)\n",
        "    return str(latest)\n",
        "\n",
        "\n",
        "def guess_algo_from_model_path(model_path: str) -> str:\n",
        "    name = Path(model_path).name.lower()\n",
        "    if 'mappo' in name or 'ppo' in name:\n",
        "        return 'mappo'\n",
        "    return 'masac'\n",
        "\n",
        "\n",
        "def make_eval_output_dirs(algo_tag: str, results_root: str | Path = 'results') -> dict:\n",
        "    algo_tag = _algo_tag_normalize(algo_tag)\n",
        "    now = datetime.now()\n",
        "    date = now.strftime('%Y%m%d')\n",
        "    t = now.strftime('%H%M%S')\n",
        "\n",
        "    base = Path(results_root) / 'eval' / algo_tag / date / t\n",
        "    models_dir = base / 'models'\n",
        "    figs_dir = base / 'figs'\n",
        "    base.mkdir(parents=True, exist_ok=True)\n",
        "    models_dir.mkdir(parents=True, exist_ok=True)\n",
        "    figs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    return {\n",
        "        'base': base,\n",
        "        'models_dir': models_dir,\n",
        "        'figs_dir': figs_dir,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd7c29aa",
      "metadata": {},
      "source": [
        "## 1) é€‰æ‹©æ¨¡å‹\n",
        "\n",
        "ä½ å¯ä»¥äºŒé€‰ä¸€ï¼š\n",
        "- æ–¹å¼ Aï¼šæ‰‹åŠ¨æŒ‡å®š `MODEL_PATH`\n",
        "- æ–¹å¼ Bï¼šåªæŒ‡å®š `ALGO_TAG`ï¼Œè‡ªåŠ¨åŠ è½½è¯¥ç®—æ³•æœ€æ–°æ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ccb725c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== æ–¹å¼ Aï¼ˆæ‰‹åŠ¨ï¼‰==========\n",
        "MODEL_PATH = ''  # e.g. '/root/.../results/masac/20251228/231613/models/best_model_ctde_14f_masac_light.pt'\n",
        "\n",
        "# ========== æ–¹å¼ Bï¼ˆè‡ªåŠ¨ï¼‰==========\n",
        "ALGO_TAG = 'masac'  # 'masac' or 'mappo'\n",
        "AUTO_LOAD_LATEST = True\n",
        "\n",
        "# æ¨¡å‹æ–‡ä»¶ååŒ¹é…è§„åˆ™ï¼ˆä¸€èˆ¬ä¸ç”¨æ”¹ï¼‰\n",
        "MODEL_GLOB = 'best_model*.pt'\n",
        "\n",
        "# -------- å†³ç­–é€»è¾‘ --------\n",
        "if MODEL_PATH:\n",
        "    model_path = MODEL_PATH\n",
        "    algo_tag = guess_algo_from_model_path(model_path)\n",
        "else:\n",
        "    algo_tag = _algo_tag_normalize(ALGO_TAG)\n",
        "    if AUTO_LOAD_LATEST:\n",
        "        model_path = find_latest_model_in_results(algo_tag, results_root='results', pattern=MODEL_GLOB)\n",
        "    else:\n",
        "        raise ValueError('AUTO_LOAD_LATEST=False æ—¶è¯·æ‰‹åŠ¨å¡«å†™ MODEL_PATH')\n",
        "\n",
        "model_path = str(Path(model_path).expanduser())\n",
        "print('Selected algo_tag:', algo_tag)\n",
        "print('Selected model_path:', model_path)\n",
        "assert Path(model_path).exists(), f'æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5a46a31",
      "metadata": {},
      "source": [
        "## 2) åŠ è½½æ¨¡å‹å¹¶è¯„ä¼°ï¼ˆè¾“å‡ºæ•°å€¼æŒ‡æ ‡ï¼‰\n",
        "\n",
        "é»˜è®¤ä¼šè¯„ä¼° `num_eval_episodes` ä¸ª episodeï¼Œè¾“å‡ºå¹³å‡ reward / å¹³å‡è·Ÿè¸ªè¯¯å·® / å¹³å‡é€šä¿¡ç‡ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64816ace",
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¯„ä¼°å‚æ•°\n",
        "num_eval_episodes = 10\n",
        "seed_for_eval = SEED\n",
        "\n",
        "# ç”»å›¾æ—¶æœ€å¤šå±•ç¤ºå¤šå°‘ä¸ªè·Ÿéšè€…ï¼šNone=å…¨éƒ¨ï¼›ä¾‹å¦‚ 5=åªç”»å‰ 5 ä¸ª\n",
        "MAX_PLOT_FOLLOWERS = None\n",
        "\n",
        "set_seed(seed_for_eval)\n",
        "\n",
        "# ç¯å¢ƒ/æ‹“æ‰‘\n",
        "topology = CommunicationTopology(NUM_FOLLOWERS, num_pinned=NUM_PINNED)\n",
        "env = ModelFreeEnv(topology)\n",
        "\n",
        "# agent\n",
        "if algo_tag == 'mappo':\n",
        "    agent = CTDEMAPPOAgent(topology, use_amp=False)\n",
        "else:\n",
        "    agent = CTDESACAgent(topology, use_amp=False)\n",
        "\n",
        "agent.load(model_path)\n",
        "\n",
        "metrics = evaluate_agent(agent, env, num_episodes=num_eval_episodes)\n",
        "print('Metrics:', metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05115c1c",
      "metadata": {},
      "source": [
        "## 3) ï¼ˆå¯é€‰ï¼‰ä¿å­˜è¯„ä¼°äº§ç‰©ï¼ˆæŒ‡æ ‡ JSON + è¯„ä¼°å›¾ï¼‰\n",
        "\n",
        "é»˜è®¤ä¸ä¿å­˜ä»»ä½•ç”Ÿæˆç‰©ï¼›æŠŠä¸‹é¢å•å…ƒæ ¼é‡Œçš„ `SAVE_OUTPUTS=True` åå†è¿è¡Œå³å¯ä¿å­˜åˆ° `results/eval/<algo>/YYYYMMDD/HHMMSS/`ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1070383",
      "metadata": {},
      "outputs": [],
      "source": [
        "# é»˜è®¤ä¸ä¿å­˜ä»»ä½•ç”Ÿæˆç‰©ï¼›éœ€è¦è½ç›˜æ—¶æ”¹æˆ True å¹¶é‡æ–°è¿è¡Œæœ¬å•å…ƒæ ¼\n",
        "SAVE_OUTPUTS = False\n",
        "\n",
        "if SAVE_OUTPUTS:\n",
        "    out = make_eval_output_dirs(algo_tag, results_root='results')\n",
        "    print('Eval outputs ->', out['base'])\n",
        "\n",
        "    # 1) ä¿å­˜æŒ‡æ ‡\n",
        "    metrics_path = out['base'] / 'metrics.json'\n",
        "    payload = {\n",
        "        'algo': algo_tag,\n",
        "        'model_path': model_path,\n",
        "        'seed': seed_for_eval,\n",
        "        'num_eval_episodes': num_eval_episodes,\n",
        "        'metrics': metrics,\n",
        "        'timestamp': datetime.now().isoformat(timespec='seconds'),\n",
        "    }\n",
        "    metrics_path.write_text(json.dumps(payload, indent=2, ensure_ascii=False), encoding='utf-8')\n",
        "    print('Saved metrics ->', metrics_path)\n",
        "\n",
        "    # 2) ä¿å­˜è¯„ä¼°å›¾\n",
        "    fig_path = out['figs_dir'] / f'final_evaluation_{algo_tag}.png'\n",
        "    plot_evaluation(agent, topology, num_tests=3, save_path=str(fig_path), max_plot_followers=MAX_PLOT_FOLLOWERS)\n",
        "    print('Saved figure ->', fig_path)\n",
        "else:\n",
        "    print('SAVE_OUTPUTS=Falseï¼šæœ¬æ¬¡ä»…è¯„ä¼°å¹¶æ‰“å° metricsï¼Œä¸ä¿å­˜ metrics.json/å›¾ç‰‡ã€‚')\n",
        "    # ä»å¯åœ¨ Notebook é‡Œç›´æ¥çœ‹å›¾ï¼ˆä¸è½ç›˜ï¼‰\n",
        "    plot_evaluation(agent, topology, num_tests=3, save_path=None, max_plot_followers=MAX_PLOT_FOLLOWERS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "829768cd",
      "metadata": {},
      "source": [
        "## å¯é€‰ï¼šå›ºå®šç¯å¢ƒéšæœºåŒ–ï¼ˆåšå¯å¤ç°å¯¹æ¯”ï¼‰\n",
        "\n",
        "ä½ çš„ç¯å¢ƒé»˜è®¤ `reset()` ä¼šéšæœºåŒ– leader å‚æ•°/åˆå§‹çŠ¶æ€/æ‹“æ‰‘ã€‚\n",
        "å¦‚æœä½ æƒ³åœ¨**åŒä¸€ä¸ªå›ºå®šåœºæ™¯**é‡Œå¯¹æ¯”å¤šä¸ªæ¨¡å‹ï¼Œå¯ä»¥æŠŠéšæœºåŒ–å…³æ‰ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1bfa421",
      "metadata": {},
      "outputs": [],
      "source": [
        "# å…³é—­éšæœºåŒ–ï¼ˆå¯é€‰ï¼‰\n",
        "env_fixed = ModelFreeEnv(topology)\n",
        "env_fixed.batched_env.randomize_leader = False\n",
        "env_fixed.batched_env.randomize_follower = False\n",
        "env_fixed.batched_env.randomize_topology = False\n",
        "\n",
        "metrics_fixed = evaluate_agent(agent, env_fixed, num_episodes=5)\n",
        "print('Fixed-scenario metrics:', metrics_fixed)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
