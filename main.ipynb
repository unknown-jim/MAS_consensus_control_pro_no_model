{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0bf3d-c1f5-4fc2-84a8-aef9f04e9031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # ğŸ¯ CTDE Leader-Follower MAS Event-Triggered Consensus\n",
    "# \n",
    "# **CTDE æ¶æ„ï¼ˆCentralized Training Decentralized Executionï¼‰**\n",
    "# - **Actor**: åˆ†æ•£å¼ï¼Œåªä½¿ç”¨æœ¬åœ°è§‚æµ‹\n",
    "# - **Critic**: é›†ä¸­å¼ï¼Œä½¿ç”¨å…¨å±€çŠ¶æ€ + è”åˆåŠ¨ä½œ\n",
    "# - **éšæœºåˆå§‹åŒ–**: æ¯ä¸ª episode éšæœºåŒ–é¢†å¯¼è€…åŠ¨åŠ›å­¦å’Œè·Ÿéšè€…åˆå§‹çŠ¶æ€\n",
    "\n",
    "# %%\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from config import print_config, NUM_FOLLOWERS, NUM_PINNED\n",
    "print_config()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## ğŸ² Randomization Settings\n",
    "# \n",
    "# æ¯ä¸ª episode éšæœºåˆå§‹åŒ–é¢†å¯¼è€…åŠ¨åŠ›å­¦å’Œè·Ÿéšè€…çŠ¶æ€ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›\n",
    "\n",
    "# %%\n",
    "from config import (\n",
    "    RANDOMIZE_LEADER, RANDOMIZE_FOLLOWER,\n",
    "    LEADER_AMPLITUDE_RANGE, LEADER_OMEGA_RANGE, LEADER_PHASE_RANGE,\n",
    "    FOLLOWER_INIT_POS_STD_RANGE, FOLLOWER_INIT_VEL_STD_RANGE,\n",
    "    LEADER_AMPLITUDE, LEADER_OMEGA, LEADER_PHASE\n",
    ")\n",
    "\n",
    "print(\"ğŸ² Randomization Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nğŸ“ Leader Dynamics Randomization: {'âœ… Enabled' if RANDOMIZE_LEADER else 'âŒ Disabled'}\")\n",
    "if RANDOMIZE_LEADER:\n",
    "    print(f\"   Amplitude range: {LEADER_AMPLITUDE_RANGE} (base: {LEADER_AMPLITUDE})\")\n",
    "    print(f\"   Omega range: {LEADER_OMEGA_RANGE} (base: {LEADER_OMEGA})\")\n",
    "    print(f\"   Phase range: [{LEADER_PHASE_RANGE[0]:.2f}, {LEADER_PHASE_RANGE[1]:.2f}] rad\")\n",
    "else:\n",
    "    print(f\"   Fixed amplitude: {LEADER_AMPLITUDE}\")\n",
    "    print(f\"   Fixed omega: {LEADER_OMEGA}\")\n",
    "    print(f\"   Fixed phase: {LEADER_PHASE}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Follower Init Randomization: {'âœ… Enabled' if RANDOMIZE_FOLLOWER else 'âŒ Disabled'}\")\n",
    "if RANDOMIZE_FOLLOWER:\n",
    "    print(f\"   Position std range: {FOLLOWER_INIT_POS_STD_RANGE}\")\n",
    "    print(f\"   Velocity std range: {FOLLOWER_INIT_VEL_STD_RANGE}\")\n",
    "else:\n",
    "    print(f\"   Fixed position std: 0.5\")\n",
    "    print(f\"   Fixed velocity std: 0.2\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## ğŸ“¡ Communication Topology (Simulation Only)\n",
    "# \n",
    "# **æ³¨æ„**ï¼šæ‹“æ‰‘ä»…ç”¨äº**æ¨¡æ‹Ÿé€šä¿¡èŒƒå›´**ï¼Œç¥ç»ç½‘ç»œä¸ä½¿ç”¨æ‹“æ‰‘ç»“æ„ï¼\n",
    "\n",
    "# %%\n",
    "from topology import CommunicationTopology\n",
    "\n",
    "topology = CommunicationTopology(NUM_FOLLOWERS, num_pinned=NUM_PINNED)\n",
    "topology.visualize()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## ğŸ” Environment Test - Verify Randomization\n",
    "\n",
    "# %%\n",
    "from environment import BatchedModelFreeEnv\n",
    "import torch\n",
    "\n",
    "# æµ‹è¯•éšæœºåˆå§‹åŒ–\n",
    "test_env = BatchedModelFreeEnv(topology, num_envs=4)\n",
    "\n",
    "print(\"ğŸ§ª Testing Randomization (4 parallel environments):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for test_round in range(3):\n",
    "    _ = test_env.reset()\n",
    "    \n",
    "    print(f\"\\nğŸ“ Reset #{test_round + 1}:\")\n",
    "    print(f\"   Leader Amplitudes: {test_env.leader_amplitude.cpu().numpy().round(3)}\")\n",
    "    print(f\"   Leader Omegas: {test_env.leader_omega.cpu().numpy().round(3)}\")\n",
    "    print(f\"   Leader Phases: {test_env.leader_phase.cpu().numpy().round(3)}\")\n",
    "    print(f\"   Follower Pos Std: {test_env.positions[:, 1:].std(dim=1).cpu().numpy().round(3)}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## ğŸš€ CTDE Training\n",
    "# \n",
    "# **å…³é”®ç‰¹æ€§ï¼š**\n",
    "# - âœ… æ¯ä¸ª episode éšæœºåŒ–é¢†å¯¼è€…åŠ¨åŠ›å­¦\n",
    "# - âœ… æ¯ä¸ª episode éšæœºåŒ–è·Ÿéšè€…åˆå§‹çŠ¶æ€\n",
    "# - âœ… Actor åªç”¨æœ¬åœ°è§‚æµ‹ï¼ˆåˆ†æ•£æ‰§è¡Œï¼‰\n",
    "# - âœ… Critic ç”¨å…¨å±€çŠ¶æ€ï¼ˆé›†ä¸­è®­ç»ƒï¼‰\n",
    "\n",
    "# %%\n",
    "from train import train\n",
    "from config import NUM_EPISODES\n",
    "\n",
    "trained_agent, topology, dashboard = train(\n",
    "    num_episodes=NUM_EPISODES, \n",
    "    vis_interval=5,\n",
    "    show_dashboard=True\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## ğŸ“Š Evaluation on Different Scenarios\n",
    "# \n",
    "# è¯„ä¼°æ™ºèƒ½ä½“åœ¨**ä¸åŒé¢†å¯¼è€…åŠ¨åŠ›å­¦**ä¸‹çš„æ³›åŒ–èƒ½åŠ›\n",
    "\n",
    "# %%\n",
    "from utils import plot_evaluation, collect_trajectory, evaluate_agent\n",
    "from environment import ModelFreeEnv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# æ ‡å‡†è¯„ä¼°\n",
    "print(\"ğŸ“Š Standard Evaluation (Randomized Scenarios):\")\n",
    "print(\"=\" * 50)\n",
    "plot_evaluation(trained_agent, topology, num_tests=3, save_path='final_evaluation_ctde.png')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## ğŸ”¬ Generalization Test - Different Leader Dynamics\n",
    "\n",
    "# %%\n",
    "# æµ‹è¯•ä¸åŒé¢†å¯¼è€…åŠ¨åŠ›å­¦ä¸‹çš„æ€§èƒ½\n",
    "def test_specific_dynamics(agent, topology, amplitude, omega, num_steps=600):\n",
    "    \"\"\"æµ‹è¯•ç‰¹å®šé¢†å¯¼è€…åŠ¨åŠ›å­¦ä¸‹çš„æ€§èƒ½\"\"\"\n",
    "    from environment import ModelFreeEnv\n",
    "    from config import DEVICE\n",
    "    \n",
    "    env = ModelFreeEnv(topology)\n",
    "    \n",
    "    # æ‰‹åŠ¨è®¾ç½®é¢†å¯¼è€…å‚æ•°ï¼ˆè¦†ç›–éšæœºåŒ–ï¼‰\n",
    "    env.batched_env.leader_amplitude[0] = amplitude\n",
    "    env.batched_env.leader_omega[0] = omega\n",
    "    env.batched_env.leader_phase[0] = 0.0\n",
    "    \n",
    "    state = env.reset()\n",
    "    # é‡æ–°è®¾ç½®å‚æ•°ï¼ˆreset ä¼šé‡æ–°éšæœºåŒ–ï¼‰\n",
    "    env.batched_env.leader_amplitude[0] = amplitude\n",
    "    env.batched_env.leader_omega[0] = omega\n",
    "    env.batched_env.leader_phase[0] = 0.0\n",
    "    \n",
    "    total_reward = 0\n",
    "    total_error = 0\n",
    "    total_comm = 0\n",
    "    \n",
    "    times = [0]\n",
    "    leader_pos = [env.positions[0].item()]\n",
    "    follower_pos = [env.positions[1:].cpu().numpy()]\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        action = agent.select_action(state, deterministic=True)\n",
    "        state, reward, _, info = env.step(action)\n",
    "        \n",
    "        total_reward += reward\n",
    "        total_error += info['tracking_error']\n",
    "        total_comm += info['comm_rate']\n",
    "        \n",
    "        times.append(env.t)\n",
    "        leader_pos.append(env.positions[0].item())\n",
    "        follower_pos.append(env.positions[1:].cpu().numpy())\n",
    "    \n",
    "    return {\n",
    "        'reward': total_reward,\n",
    "        'avg_error': total_error / num_steps,\n",
    "        'avg_comm': total_comm / num_steps,\n",
    "        'times': np.array(times),\n",
    "        'leader_pos': np.array(leader_pos),\n",
    "        'follower_pos': np.array(follower_pos)\n",
    "    }\n",
    "\n",
    "# æµ‹è¯•ä¸åŒåœºæ™¯\n",
    "test_scenarios = [\n",
    "    {'name': 'Slow & Small', 'amplitude': 1.0, 'omega': 0.3},\n",
    "    {'name': 'Medium', 'amplitude': 2.0, 'omega': 0.5},\n",
    "    {'name': 'Fast & Large', 'amplitude': 3.0, 'omega': 0.8},\n",
    "    {'name': 'Extra Fast', 'amplitude': 2.5, 'omega': 1.0},  # è¶…å‡ºè®­ç»ƒèŒƒå›´\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ”¬ Generalization Test - Different Leader Dynamics:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Scenario':<15} | {'Amplitude':>9} | {'Omega':>7} | {'Reward':>10} | {'Avg Error':>10} | {'Comm Rate':>9}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, scenario in enumerate(test_scenarios):\n",
    "    result = test_specific_dynamics(\n",
    "        trained_agent, topology, \n",
    "        scenario['amplitude'], scenario['omega']\n",
    "    )\n",
    "    \n",
    "    print(f\"{scenario['name']:<15} | {scenario['amplitude']:>9.1f} | {scenario['omega']:>7.2f} | \"\n",
    "          f\"{result['reward']:>10.2f} | {result['avg_error']:>10.4f} | {result['avg_comm']*100:>8.1f}%\")\n",
    "    \n",
    "    # ç»˜å›¾\n",
    "    ax = axes[idx]\n",
    "    ax.plot(result['times'], result['leader_pos'], 'r-', lw=2.5, label='Leader')\n",
    "    \n",
    "    colors = plt.cm.Blues(np.linspace(0.3, 0.9, result['follower_pos'].shape[1]))\n",
    "    for i in range(min(4, result['follower_pos'].shape[1])):\n",
    "        ax.plot(result['times'], result['follower_pos'][:, i], color=colors[i], alpha=0.7, lw=1)\n",
    "    \n",
    "    avg_follower = result['follower_pos'].mean(axis=1)\n",
    "    ax.plot(result['times'], avg_follower, 'g--', lw=2, label='Avg Follower')\n",
    "    \n",
    "    ax.set_title(f\"{scenario['name']} (A={scenario['amplitude']}, Ï‰={scenario['omega']})\\n\"\n",
    "                f\"Error: {result['avg_error']:.4f}, Comm: {result['avg_comm']*100:.1f}%\", fontsize=10)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Position')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('generalization_test.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"âœ… Generalization test complete!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## ğŸ“ˆ CTDE State Space Analysis\n",
    "\n",
    "# %%\n",
    "from config import (\n",
    "    STATE_DIM, LOCAL_OBS_DIM, MAX_NEIGHBORS, NEIGHBOR_OBS_DIM,\n",
    "    GLOBAL_STATE_DIM, NUM_AGENTS, ACTION_DIM, NUM_FOLLOWERS\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š CTDE State Space Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ­ Actor (Decentralized Execution):\")\n",
    "print(f\"   Input: Local observation ({STATE_DIM} dim)\")\n",
    "print(f\"     - Self state: {LOCAL_OBS_DIM} dim (position, velocity)\")\n",
    "print(f\"     - Neighbor data: {MAX_NEIGHBORS} Ã— {NEIGHBOR_OBS_DIM} = {MAX_NEIGHBORS * NEIGHBOR_OBS_DIM} dim\")\n",
    "print(f\"   Output: Action ({ACTION_DIM} dim)\")\n",
    "print(f\"     - Velocity change: 1 dim\")\n",
    "print(f\"     - Communication threshold: 1 dim\")\n",
    "\n",
    "print(\"\\nğŸ¯ Critic (Centralized Training):\")\n",
    "print(f\"   Input: Global state ({GLOBAL_STATE_DIM} dim) + Joint action ({NUM_FOLLOWERS * ACTION_DIM} dim)\")\n",
    "print(f\"     - All agents' positions: {NUM_AGENTS} dim\")\n",
    "print(f\"     - All agents' velocities: {NUM_AGENTS} dim\")\n",
    "print(f\"     - All followers' actions: {NUM_FOLLOWERS} Ã— {ACTION_DIM} = {NUM_FOLLOWERS * ACTION_DIM} dim\")\n",
    "print(f\"   Output: Q-value (1 dim)\")\n",
    "\n",
    "print(\"\\nğŸ”‘ Key CTDE Properties:\")\n",
    "print(\"   âœ… Actor does NOT access global state during execution\")\n",
    "print(\"   âœ… Critic has full observability during training\")\n",
    "print(\"   âœ… Each agent uses shared policy (parameter sharing)\")\n",
    "print(\"   âœ… Randomized scenarios improve generalization\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## ğŸ’¾ Save Results\n",
    "\n",
    "# %%\n",
    "# ä¿å­˜è®­ç»ƒæ‘˜è¦\n",
    "if dashboard:\n",
    "    summary = dashboard.get_summary()\n",
    "    print(\"\\nğŸ“Š Training Summary:\")\n",
    "    print(f\"   Best Reward: {summary['best_reward']:.2f}\")\n",
    "    print(f\"   Final Reward: {summary['final_reward']:.2f}\")\n",
    "    print(f\"   Final Tracking Error: {summary['final_tracking_error']:.4f}\")\n",
    "    print(f\"   Final Comm Rate: {summary['final_comm_rate']*100:.1f}%\")\n",
    "    print(f\"   Total Episodes: {summary['total_episodes']}\")\n",
    "    print(f\"   Elapsed Time: {summary['elapsed_time']:.1f}s\")\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹ä¿¡æ¯\n",
    "from config import SAVE_MODEL_PATH\n",
    "print(f\"\\nğŸ’¾ Model saved to: {SAVE_MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
