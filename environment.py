"""
é¢†å¯¼è€…-è·Ÿéšè€…å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç¯å¢ƒ - CTDE ç‰ˆæœ¬ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰

æ–°å¢åŠŸèƒ½ï¼š
- æ¯ä¸ª episode éšæœºåŒ–é¢†å¯¼è€…åŠ¨åŠ›å­¦å‚æ•°ï¼ˆæŒ¯å¹…ã€è§’é¢‘ç‡ã€ç›¸ä½ï¼‰
- æ¯ä¸ª episode éšæœºåŒ–è·Ÿéšè€…åˆå§‹çŠ¶æ€åˆ†å¸ƒ
- æ¯ä¸ª episode éšæœºåŒ–é€šä¿¡æ‹“æ‰‘ï¼ˆä¿è¯è¿é€šæ€§ï¼‰
"""
import torch

from config import (
    DEVICE, DT, MAX_STEPS,
    LOCAL_OBS_DIM, NEIGHBOR_OBS_DIM, MAX_NEIGHBORS, STATE_DIM,
    SELF_ROLE_DIM, NEIGHBOR_ROLE_DIM, NEIGHBOR_FEAT_DIM,
    COMM_PENALTY, THRESHOLD_MIN, THRESHOLD_MAX,
    TRACKING_PENALTY_SCALE, TRACKING_PENALTY_MAX, COMM_WEIGHT_DECAY,
    IMPROVEMENT_SCALE, IMPROVEMENT_CLIP,
    LEADER_AMPLITUDE, LEADER_OMEGA, LEADER_PHASE,
    POS_LIMIT, VEL_LIMIT,
    REWARD_MIN, REWARD_MAX, USE_SOFT_REWARD_SCALING,
    TH_SCALE, V_SCALE, NUM_AGENTS, GLOBAL_STATE_DIM,
    GLOBAL_STATE_INCLUDE_BROADCAST,
    GLOBAL_STATE_INCLUDE_LEADER_PARAMS,
    GLOBAL_STATE_INCLUDE_TRAJ_TYPE,
    GLOBAL_STATE_INCLUDE_TIME,
    # éšæœºåŒ–å‚æ•°
    RANDOMIZE_LEADER, RANDOMIZE_FOLLOWER, RANDOMIZE_TOPOLOGY,
    LEADER_AMPLITUDE_RANGE, LEADER_OMEGA_RANGE, LEADER_PHASE_RANGE,
    FOLLOWER_INIT_POS_STD_RANGE, FOLLOWER_INIT_VEL_STD_RANGE,
    FOLLOWER_INIT_POS_STD, FOLLOWER_INIT_VEL_STD,
    LEADER_TRAJECTORY_TYPES
)


class BatchedModelFreeEnv:
    """
    æ— æ¨¡å‹æ‰¹é‡ç¯å¢ƒ - CTDE ç‰ˆæœ¬ï¼ˆéšæœºåˆå§‹åŒ– + å¤šè½¨è¿¹ç±»å‹ + æ‹“æ‰‘éšæœºåŒ–ï¼‰
    
    æ–°å¢åŠŸèƒ½ï¼š
    - get_global_state(): è¿”å›å…¨å±€çŠ¶æ€ç”¨äºé›†ä¸­å¼ Critic è®­ç»ƒ
    - æ¯ä¸ª episode éšæœºåŒ–é¢†å¯¼è€…åŠ¨åŠ›å­¦å’Œè·Ÿéšè€…åˆå§‹çŠ¶æ€
    - æ”¯æŒå¤šç§é¢†å¯¼è€…è½¨è¿¹ç±»å‹ï¼šsine, cosine, mixed, chirp
    - æ¯ä¸ª episode éšæœºåŒ–é€šä¿¡æ‹“æ‰‘ï¼ˆä¿è¯è¿é€šæ€§ï¼‰
    """
    
    def __init__(self, topology, num_envs=64):
        self.topology = topology
        self.num_envs = num_envs
        self.num_agents = topology.num_agents
        self.num_followers = topology.num_followers
        self.leader_id = topology.leader_id
        
        # é¢†å¯¼è€…åŠ¨åŠ›å­¦å‚æ•°ï¼ˆåŸºå‡†å€¼ï¼Œä¼šåœ¨ reset æ—¶éšæœºåŒ–ï¼‰
        self.leader_amplitude_base = LEADER_AMPLITUDE
        self.leader_omega_base = LEADER_OMEGA
        self.leader_phase_base = LEADER_PHASE
        
        # ğŸ”§ ä¸ºæ¯ä¸ªç¯å¢ƒå­˜å‚¨ç‹¬ç«‹çš„é¢†å¯¼è€…åŠ¨åŠ›å­¦å‚æ•°
        self.leader_amplitude = torch.full((num_envs,), LEADER_AMPLITUDE, device=DEVICE)
        self.leader_omega = torch.full((num_envs,), LEADER_OMEGA, device=DEVICE)
        self.leader_phase = torch.full((num_envs,), LEADER_PHASE, device=DEVICE)
        
        # ğŸ”§ è½¨è¿¹ç±»å‹æ”¯æŒ
        self.trajectory_types = LEADER_TRAJECTORY_TYPES
        self.type_to_id = {t: i for i, t in enumerate(self.trajectory_types)}
        self.id_to_type = {i: t for i, t in enumerate(self.trajectory_types)}
        self.trajectory_type_ids = torch.zeros(num_envs, dtype=torch.long, device=DEVICE)
        
        # éšæœºåŒ–å¼€å…³
        self.randomize_leader = RANDOMIZE_LEADER
        self.randomize_follower = RANDOMIZE_FOLLOWER
        self.randomize_topology = RANDOMIZE_TOPOLOGY
        
        # é¢†å¯¼è€…éšæœºåŒ–èŒƒå›´
        self.amplitude_range = LEADER_AMPLITUDE_RANGE
        self.omega_range = LEADER_OMEGA_RANGE
        self.phase_range = LEADER_PHASE_RANGE
        
        # è·Ÿéšè€…éšæœºåŒ–èŒƒå›´
        self.pos_std_range = FOLLOWER_INIT_POS_STD_RANGE
        self.vel_std_range = FOLLOWER_INIT_VEL_STD_RANGE
        
        self.pos_limit = POS_LIMIT
        self.vel_limit = VEL_LIMIT
        self.reward_min = REWARD_MIN
        self.reward_max = REWARD_MAX
        self.use_soft_scaling = USE_SOFT_REWARD_SCALING
        
        # å¥–åŠ±å‚æ•°
        self.comm_penalty_base = COMM_PENALTY
        self.threshold_min = THRESHOLD_MIN
        self.threshold_max = THRESHOLD_MAX
        self.tracking_penalty_scale = TRACKING_PENALTY_SCALE
        self.tracking_penalty_max = TRACKING_PENALTY_MAX
        self.comm_weight_decay = COMM_WEIGHT_DECAY
        self.improvement_scale = IMPROVEMENT_SCALE
        self.improvement_clip = IMPROVEMENT_CLIP
        
        self.th_scale = TH_SCALE
        self.v_scale = V_SCALE
        
        # é¢„è®¡ç®—é‚»å±…ç´¢å¼•
        self._precompute_neighbor_indices()
        
        # é¢„åˆ†é…çŠ¶æ€å¼ é‡
        self.positions = torch.zeros(num_envs, self.num_agents, device=DEVICE)
        self.velocities = torch.zeros(num_envs, self.num_agents, device=DEVICE)
        
        # å¹¿æ’­çŠ¶æ€ï¼ˆé‚»å±…å¯è§ï¼‰
        self.last_broadcast_pos = torch.zeros(num_envs, self.num_agents, device=DEVICE)
        self.last_broadcast_vel = torch.zeros(num_envs, self.num_agents, device=DEVICE)

        # ==================== Leader gossipï¼šleader ä¿¡æ¯åœ¨æ™ºèƒ½ä½“ä¹‹é—´ä¼ æ’­ ====================
        # å…¨å±€ leader åºåˆ—å·ï¼ˆæ¯ä¸ª env ä¸€ä»½ï¼›æ¯ step +1ï¼›reset ç½® 0ï¼‰
        self.leader_seq = torch.zeros(num_envs, dtype=torch.long, device=DEVICE)

        # æ¯ä¸ªæ™ºèƒ½ä½“â€œå½“å‰æŒæ¡çš„â€ leader ä¼°è®¡ï¼ˆç”¨äºè‡ªèº«è§‚æµ‹ & ä¸‹ä¸€æ¬¡å¹¿æ’­ï¼‰
        self.leader_est_pos = torch.zeros(num_envs, self.num_agents, device=DEVICE)
        self.leader_est_vel = torch.zeros(num_envs, self.num_agents, device=DEVICE)
        self.leader_est_seq = torch.full((num_envs, self.num_agents), -1, dtype=torch.long, device=DEVICE)

        # æ¯ä¸ªæ™ºèƒ½ä½“â€œä¸Šä¸€æ¬¡å¹¿æ’­å‡ºå»çš„â€ leader ä¼°è®¡ï¼ˆé‚»å±…åœ¨è§‚æµ‹é‡Œçœ‹åˆ°çš„æ˜¯è¿™ä»½ï¼‰
        self.last_broadcast_leader_pos = torch.zeros(num_envs, self.num_agents, device=DEVICE)
        self.last_broadcast_leader_vel = torch.zeros(num_envs, self.num_agents, device=DEVICE)
        self.last_broadcast_leader_seq = torch.full((num_envs, self.num_agents), -1, dtype=torch.long, device=DEVICE)
        
        self.t = torch.zeros(num_envs, device=DEVICE)
        
        # ä¸ºæ¯ä¸ªç¯å¢ƒå•ç‹¬å­˜å‚¨ prev_error
        self._prev_error = torch.zeros(num_envs, device=DEVICE)
        self._prev_error_valid = torch.zeros(num_envs, dtype=torch.bool, device=DEVICE)
        
        # é¢„åˆ†é…çŠ¶æ€ç¼“å­˜
        self._state_buffer = torch.zeros(num_envs, self.num_agents, STATE_DIM, device=DEVICE)
        
        # CTDEï¼šé¢„åˆ†é…å…¨å±€çŠ¶æ€ç¼“å­˜
        self._global_state_buffer = torch.zeros(num_envs, GLOBAL_STATE_DIM, device=DEVICE)
        
        self.reset()
    
    def _precompute_neighbor_indices(self, verbose=True):
        """é¢„è®¡ç®—æ¯ä¸ªæ™ºèƒ½ä½“çš„é‚»å±…ç´¢å¼•"""
        self._neighbor_indices_list = []
        self._neighbor_counts = torch.zeros(self.num_agents, dtype=torch.long, device=DEVICE)
        
        for i in range(self.num_agents):
            can_receive_mask = self.topology.adj_matrix[i, :] > 0
            indices = torch.where(can_receive_mask)[0]
            
            if len(indices) > MAX_NEIGHBORS:
                indices = indices[:MAX_NEIGHBORS]
            
            self._neighbor_indices_list.append(indices)
            self._neighbor_counts[i] = len(indices)
        
        self._padded_neighbor_indices = torch.zeros(
            self.num_agents, MAX_NEIGHBORS, dtype=torch.long, device=DEVICE
        )
        self._neighbor_valid_mask = torch.zeros(
            self.num_agents, MAX_NEIGHBORS, dtype=torch.bool, device=DEVICE
        )
        
        for i, indices in enumerate(self._neighbor_indices_list):
            num_neighbors = len(indices)
            if num_neighbors > 0:
                self._padded_neighbor_indices[i, :num_neighbors] = indices
                self._neighbor_valid_mask[i, :num_neighbors] = True
        
        self._max_actual_neighbors = int(self._neighbor_counts.max().item())
        
        # ğŸ”§ é¢„è®¡ç®—è§’è‰²ä¿¡æ¯
        self._precompute_role_info()
        
        if verbose:
            print(f"ğŸ“Š Precomputed neighbor indices:")
            print(f"   Max neighbors per agent: {self._max_actual_neighbors}")
            print(f"   Neighbor counts: {self._neighbor_counts.tolist()}")
            print(f"   Role encoding: Leader=0, Pinned=1, Normal=2")
    
    def _precompute_role_info(self, verbose=False):
        """
        ğŸ”§ é¢„è®¡ç®—è§’è‰²ä¿¡æ¯ï¼ˆone-hot ç¼–ç ï¼‰
        
        è§’è‰²å®šä¹‰ï¼š
        - 0: é¢†å¯¼è€… (Leader)
        - 1: ç›´æ¥ä¸é¢†å¯¼è€…é€šä¿¡çš„è·Ÿéšè€… (Pinned Follower)
        - 2: æ™®é€šè·Ÿéšè€… (Normal Follower)
        """
        # æ¯ä¸ªæ™ºèƒ½ä½“çš„è§’è‰² ID
        self._role_ids = torch.zeros(self.num_agents, dtype=torch.long, device=DEVICE)
        self._role_ids[0] = 0  # é¢†å¯¼è€…
        
        pinned_set = set(self.topology.pinned_followers)
        for i in range(1, self.num_agents):
            if i in pinned_set:
                self._role_ids[i] = 1  # Pinned follower
            else:
                self._role_ids[i] = 2  # Normal follower
        
        # é¢„è®¡ç®— one-hot ç¼–ç  (num_agents, 3)
        self._role_onehot = torch.zeros(self.num_agents, SELF_ROLE_DIM, device=DEVICE)
        self._role_onehot.scatter_(1, self._role_ids.unsqueeze(1), 1.0)
        
        if verbose:
            print(f"   Pinned followers: {self.topology.pinned_followers}")
            print(f"   Role IDs: {self._role_ids.tolist()}")
    
    def _leader_state_batch(self, t, env_ids=None):
        """
        æ‰¹é‡è®¡ç®—é¢†å¯¼è€…çŠ¶æ€ï¼ˆæ”¯æŒæ¯ä¸ªç¯å¢ƒç‹¬ç«‹çš„åŠ¨åŠ›å­¦å‚æ•°å’Œè½¨è¿¹ç±»å‹ï¼‰
        
        Args:
            t: æ—¶é—´å¼ é‡
            env_ids: ç¯å¢ƒç´¢å¼•ï¼ˆNone è¡¨ç¤ºæ‰€æœ‰ç¯å¢ƒï¼‰
        
        è½¨è¿¹ç±»å‹ï¼š
        - sine: A * sin(Ï‰*t + Ï†)
        - cosine: A * cos(Ï‰*t + Ï†)
        - mixed: A * (sin(Ï‰*t + Ï†) + 0.3*cos(0.5*Ï‰*t))
        - chirp: A * sin((Ï‰ + 0.1*t)*t + Ï†)  å˜é¢‘ä¿¡å·
        """
        if env_ids is None:
            amplitude = self.leader_amplitude
            omega = self.leader_omega
            phase = self.leader_phase
            type_ids = self.trajectory_type_ids
            num_envs = self.num_envs
        else:
            amplitude = self.leader_amplitude[env_ids]
            omega = self.leader_omega[env_ids]
            phase = self.leader_phase[env_ids]
            type_ids = self.trajectory_type_ids[env_ids]
            num_envs = int(env_ids.numel()) if isinstance(env_ids, torch.Tensor) else int(len(env_ids))
        
        pos = torch.zeros(num_envs, device=DEVICE)
        vel = torch.zeros(num_envs, device=DEVICE)
        
        # Sine è½¨è¿¹
        sine_mask = type_ids == self.type_to_id.get('sine', 0)
        if sine_mask.any():
            pos[sine_mask] = amplitude[sine_mask] * torch.sin(omega[sine_mask] * t[sine_mask] + phase[sine_mask])
            vel[sine_mask] = amplitude[sine_mask] * omega[sine_mask] * torch.cos(omega[sine_mask] * t[sine_mask] + phase[sine_mask])
        
        # Cosine è½¨è¿¹
        cosine_mask = type_ids == self.type_to_id.get('cosine', 1)
        if cosine_mask.any():
            pos[cosine_mask] = amplitude[cosine_mask] * torch.cos(omega[cosine_mask] * t[cosine_mask] + phase[cosine_mask])
            vel[cosine_mask] = -amplitude[cosine_mask] * omega[cosine_mask] * torch.sin(omega[cosine_mask] * t[cosine_mask] + phase[cosine_mask])
        
        # Mixed è½¨è¿¹
        mixed_mask = type_ids == self.type_to_id.get('mixed', 2)
        if mixed_mask.any():
            t_m = t[mixed_mask]
            A_m = amplitude[mixed_mask]
            omega_m = omega[mixed_mask]
            phi_m = phase[mixed_mask]
            pos[mixed_mask] = A_m * (torch.sin(omega_m * t_m + phi_m) + 0.3 * torch.cos(0.5 * omega_m * t_m))
            vel[mixed_mask] = A_m * (omega_m * torch.cos(omega_m * t_m + phi_m) - 0.15 * omega_m * torch.sin(0.5 * omega_m * t_m))
        
        # Chirp è½¨è¿¹ï¼ˆå˜é¢‘ä¿¡å·ï¼‰
        chirp_mask = type_ids == self.type_to_id.get('chirp', 3)
        if chirp_mask.any():
            t_c = t[chirp_mask]
            A_c = amplitude[chirp_mask]
            omega_c = omega[chirp_mask]
            phi_c = phase[chirp_mask]
            chirp_rate = 0.1
            inst_phase = (omega_c + chirp_rate * t_c) * t_c + phi_c
            inst_freq = omega_c + 2 * chirp_rate * t_c
            pos[chirp_mask] = A_c * torch.sin(inst_phase)
            vel[chirp_mask] = A_c * inst_freq * torch.cos(inst_phase)
        
        return pos, vel
    
    def _randomize_leader_dynamics(self, env_ids):
        """
        ğŸ”§ éšæœºåŒ–é¢†å¯¼è€…åŠ¨åŠ›å­¦å‚æ•°å’Œè½¨è¿¹ç±»å‹
        
        Args:
            env_ids: éœ€è¦éšæœºåŒ–çš„ç¯å¢ƒç´¢å¼•
        """
        # env_ids é€šå¸¸æ˜¯ GPU tensorï¼Œè¿™é‡Œç”¨ numel() æ›´ç¨³
        num_envs = int(env_ids.numel()) if isinstance(env_ids, torch.Tensor) else len(env_ids)
        
        # éšæœºæŒ¯å¹…
        self.leader_amplitude[env_ids] = torch.empty(num_envs, device=DEVICE).uniform_(
            self.amplitude_range[0], self.amplitude_range[1]
        )
        
        # éšæœºè§’é¢‘ç‡
        self.leader_omega[env_ids] = torch.empty(num_envs, device=DEVICE).uniform_(
            self.omega_range[0], self.omega_range[1]
        )
        
        # éšæœºç›¸ä½
        self.leader_phase[env_ids] = torch.empty(num_envs, device=DEVICE).uniform_(
            self.phase_range[0], self.phase_range[1]
        )
        
        # ğŸ”§ éšæœºè½¨è¿¹ç±»å‹ï¼ˆé¿å… numpy -> torch çš„ CPU/GPU å¾€è¿”ï¼‰
        self.trajectory_type_ids[env_ids] = torch.randint(
            low=0,
            high=len(self.trajectory_types),
            size=(num_envs,),
            device=DEVICE,
            dtype=torch.long,
        )
    
    def _randomize_follower_init(self, env_ids, leader_pos, leader_vel):
        """
        ğŸ”§ éšæœºåŒ–è·Ÿéšè€…åˆå§‹çŠ¶æ€
        
        Args:
            env_ids: éœ€è¦éšæœºåŒ–çš„ç¯å¢ƒç´¢å¼•
            leader_pos: é¢†å¯¼è€…åˆå§‹ä½ç½®
            leader_vel: é¢†å¯¼è€…åˆå§‹é€Ÿåº¦
        """
        num_envs = int(env_ids.numel()) if isinstance(env_ids, torch.Tensor) else int(len(env_ids))
        
        # ä¸ºæ¯ä¸ªç¯å¢ƒéšæœºç”Ÿæˆä½ç½®å’Œé€Ÿåº¦çš„æ ‡å‡†å·®
        pos_std = torch.empty(num_envs, 1, device=DEVICE).uniform_(
            self.pos_std_range[0], self.pos_std_range[1]
        )
        vel_std = torch.empty(num_envs, 1, device=DEVICE).uniform_(
            self.vel_std_range[0], self.vel_std_range[1]
        )
        
        # ç”Ÿæˆéšæœºåç§»
        pos_offset = torch.randn(num_envs, self.num_followers, device=DEVICE) * pos_std
        vel_offset = torch.randn(num_envs, self.num_followers, device=DEVICE) * vel_std
        
        # è®¾ç½®è·Ÿéšè€…åˆå§‹çŠ¶æ€
        self.positions[env_ids, 1:] = leader_pos.unsqueeze(1) + pos_offset
        self.velocities[env_ids, 1:] = leader_vel.unsqueeze(1) + vel_offset
    
    def get_global_state(self):
        """CTDEï¼šè·å–å…¨å±€çŠ¶æ€ï¼ˆç”¨äºé›†ä¸­å¼ Criticï¼‰ã€‚

        æ³¨æ„ï¼šä¸ºäº†è®© critic è¾“å…¥æ›´æ¥è¿‘ Markov çŠ¶æ€ï¼ˆå°¤å…¶åœ¨ RANDOMIZE_* å¼€å¯æ—¶ï¼‰ï¼Œ
        è¿™é‡Œæ”¯æŒæŠŠâ€œé€šä¿¡å¹¿æ’­è®°å¿†/é¢†å¯¼è€…å‚æ•°/è½¨è¿¹ç±»å‹/æ—¶é—´â€ä¹Ÿæ‹¼è¿› global stateã€‚

        Returns:
            global_state: (num_envs, global_state_dim)
        """
        # ä½¿ç”¨ offset é¡ºåºå†™å…¥ï¼Œé¿å… hardcode çš„ stride å‡è®¾
        offset = 0

        # 1) å½“å‰çœŸå®çŠ¶æ€ï¼ˆå½’ä¸€åŒ–ï¼‰: pos, vel
        self._global_state_buffer[:, offset:offset + self.num_agents] = self.positions / self.pos_limit
        offset += self.num_agents
        self._global_state_buffer[:, offset:offset + self.num_agents] = self.velocities / self.vel_limit
        offset += self.num_agents

        # 2) å¹¿æ’­è®°å¿†ï¼ˆå½’ä¸€åŒ–ï¼‰: last_broadcast_pos, last_broadcast_vel
        if GLOBAL_STATE_INCLUDE_BROADCAST:
            self._global_state_buffer[:, offset:offset + self.num_agents] = self.last_broadcast_pos / self.pos_limit
            offset += self.num_agents
            self._global_state_buffer[:, offset:offset + self.num_agents] = self.last_broadcast_vel / self.vel_limit
            offset += self.num_agents

        # 3) é¢†å¯¼è€…å‚æ•°ï¼šA, Ï‰, Ï†ï¼ˆæ¯ä¸ª env ä¸€ä»½ï¼‰
        if GLOBAL_STATE_INCLUDE_LEADER_PARAMS:
            self._global_state_buffer[:, offset] = self.leader_amplitude / (self.amplitude_range[1] + 1e-8)
            offset += 1
            self._global_state_buffer[:, offset] = self.leader_omega / (self.omega_range[1] + 1e-8)
            offset += 1
            # phase å½’ä¸€åŒ–åˆ° [0,1]
            self._global_state_buffer[:, offset] = self.leader_phase / (2.0 * 3.14159265)
            offset += 1

        # 4) è½¨è¿¹ç±»å‹ one-hot
        if GLOBAL_STATE_INCLUDE_TRAJ_TYPE:
            k = len(self.trajectory_types)
            # (E,) -> one-hot (E, k)
            onehot = torch.zeros(self.num_envs, k, device=DEVICE, dtype=self._global_state_buffer.dtype)
            onehot.scatter_(1, self.trajectory_type_ids.unsqueeze(1), 1.0)
            self._global_state_buffer[:, offset:offset + k] = onehot
            offset += k

        # 5) æ—¶é—´ï¼ˆ0~1ï¼‰
        if GLOBAL_STATE_INCLUDE_TIME:
            denom = float(MAX_STEPS) * float(DT) + 1e-8
            self._global_state_buffer[:, offset] = (self.t / denom).clamp(0.0, 1.0)
            offset += 1

        return self._global_state_buffer.clone()
    
    def reset(self, env_ids=None):
        """
        é‡ç½®ç¯å¢ƒï¼ˆæ”¯æŒéšæœºåˆå§‹åŒ–ï¼‰
        
        Args:
            env_ids: è¦é‡ç½®çš„ç¯å¢ƒç´¢å¼•ï¼ˆNone è¡¨ç¤ºæ‰€æœ‰ç¯å¢ƒï¼‰
        """
        if env_ids is None:
            env_ids = torch.arange(self.num_envs, device=DEVICE)
        
        # env_ids å¯èƒ½æ˜¯ GPU tensor / CPU tensor / listï¼›è¿™é‡Œç»Ÿä¸€ç”¨â€œå®é™…é‡ç½®æ•°é‡â€
        if isinstance(env_ids, torch.Tensor):
            num_reset = int(env_ids.numel())
        else:
            num_reset = int(len(env_ids))
        
        # é‡ç½®æ—¶é—´
        self.t[env_ids] = 0.0
        
        # ğŸ”§ éšæœºåŒ–æ‹“æ‰‘ç»“æ„ï¼ˆä»…åœ¨é‡ç½®æ‰€æœ‰ç¯å¢ƒæ—¶ï¼‰
        if self.randomize_topology and (env_ids is None or len(env_ids) == self.num_envs):
            self._randomize_topology()
        
        # ğŸ”§ éšæœºåŒ–é¢†å¯¼è€…åŠ¨åŠ›å­¦å‚æ•°
        if self.randomize_leader:
            self._randomize_leader_dynamics(env_ids)
        
        # è®¡ç®—é¢†å¯¼è€…åˆå§‹çŠ¶æ€
        leader_pos, leader_vel = self._leader_state_batch(self.t[env_ids], env_ids)
        
        self.positions[env_ids, 0] = leader_pos
        self.velocities[env_ids, 0] = leader_vel
        
        # ğŸ”§ éšæœºåŒ–è·Ÿéšè€…åˆå§‹çŠ¶æ€
        if self.randomize_follower:
            self._randomize_follower_init(env_ids, leader_pos, leader_vel)
        else:
            # ä½¿ç”¨å›ºå®šçš„åˆå§‹åˆ†å¸ƒï¼ˆä» config è¯»å–ï¼Œé¿å… notebook/ç¯å¢ƒä¸ä¸€è‡´ï¼‰
            init_pos_std = float(FOLLOWER_INIT_POS_STD)
            init_vel_std = float(FOLLOWER_INIT_VEL_STD)
            self.positions[env_ids, 1:] = leader_pos.unsqueeze(1) + torch.randn(
                num_reset, self.num_followers, device=DEVICE
            ) * init_pos_std
            self.velocities[env_ids, 1:] = leader_vel.unsqueeze(1) + torch.randn(
                num_reset, self.num_followers, device=DEVICE
            ) * init_vel_std
        
        # é™åˆ¶åœ¨è¾¹ç•Œå†…
        self.positions[env_ids] = torch.clamp(self.positions[env_ids], -self.pos_limit, self.pos_limit)
        self.velocities[env_ids] = torch.clamp(self.velocities[env_ids], -self.vel_limit, self.vel_limit)
        
        # é‡ç½®å¹¿æ’­çŠ¶æ€
        self.last_broadcast_pos[env_ids] = self.positions[env_ids].clone()
        self.last_broadcast_vel[env_ids] = self.velocities[env_ids].clone()

        # ==================== leader gossip åˆå§‹åŒ– ====================
        self.leader_seq[env_ids] = 0

        # ä»…åœ¨â€œå½“å‰æ‹“æ‰‘å…è®¸æ¥æ”¶ leaderâ€çš„æ™ºèƒ½ä½“ä¸Šåˆå§‹åŒ– leader ä¼°è®¡ï¼ˆå…¶ä½™ä¸ºæœªçŸ¥ -1ï¼‰
        can_receive_leader = (self.topology.adj_matrix[:, self.leader_id] > 0)
        if isinstance(can_receive_leader, torch.Tensor):
            can_receive_leader = can_receive_leader.to(device=DEVICE)
        can_receive_leader[self.leader_id] = True

        # æ¸…ç©ºå¹¶å†™å…¥
        self.leader_est_pos[env_ids].zero_()
        self.leader_est_vel[env_ids].zero_()
        self.leader_est_seq[env_ids].fill_(-1)

        # å…è®¸æ¥æ”¶ leader çš„èŠ‚ç‚¹ï¼šseq=0, est=leader çœŸå€¼
        mask = can_receive_leader.unsqueeze(0).expand(num_reset, -1)
        leader_pos_full = leader_pos.unsqueeze(1).expand(num_reset, self.num_agents)
        leader_vel_full = leader_vel.unsqueeze(1).expand(num_reset, self.num_agents)

        self.leader_est_pos[env_ids] = torch.where(mask, leader_pos_full, self.leader_est_pos[env_ids])
        self.leader_est_vel[env_ids] = torch.where(mask, leader_vel_full, self.leader_est_vel[env_ids])
        self.leader_est_seq[env_ids] = torch.where(mask, torch.zeros_like(self.leader_est_seq[env_ids]), self.leader_est_seq[env_ids])

        # åˆå§‹å¹¿æ’­åŒ…é‡Œçš„ leader ä¿¡æ¯ï¼šç”¨å„è‡ªå½“å‰ä¼°è®¡å¡«å……
        self.last_broadcast_leader_pos[env_ids] = self.leader_est_pos[env_ids]
        self.last_broadcast_leader_vel[env_ids] = self.leader_est_vel[env_ids]
        self.last_broadcast_leader_seq[env_ids] = self.leader_est_seq[env_ids]
        
        # åªé‡ç½®æŒ‡å®šç¯å¢ƒçš„ prev_error
        self._prev_error[env_ids] = 0.0
        self._prev_error_valid[env_ids] = False
        
        return self._get_state_optimized()
    
    def _randomize_topology(self):
        """
        ğŸ”§ éšæœºåŒ–æ‹“æ‰‘ç»“æ„å¹¶æ›´æ–°ç›¸å…³ç¼“å­˜
        """
        # è°ƒç”¨æ‹“æ‰‘çš„éšæœºåŒ–æ–¹æ³•
        self.topology.randomize()
        
        # é‡æ–°è®¡ç®—é‚»å±…ç´¢å¼•å’Œè§’è‰²ä¿¡æ¯ï¼ˆé™é»˜æ¨¡å¼ï¼‰
        self._precompute_neighbor_indices(verbose=False)
    
    def _get_state_optimized(self):
        """è·å–æœ¬åœ°çŠ¶æ€ï¼ˆç”¨äºåˆ†æ•£å¼ Actorï¼‰ã€‚

        çŠ¶æ€ç»“æ„ï¼ˆæ¯ä¸ªæ™ºèƒ½ä½“ï¼‰:
        - [0:2] è‡ªèº«ä½ç½®ã€é€Ÿåº¦ï¼ˆå½’ä¸€åŒ–ï¼‰
        - [2:6] è‡ªèº«å½“å‰æŒæ¡çš„ leader ä¼°è®¡ï¼ˆå½’ä¸€åŒ–ï¼‰:
            - [2] leader_pos_est
            - [3] leader_vel_est
            - [4] leader_seq_norm
            - [5] leader_age_norm
        - [LOCAL_OBS_DIM:LOCAL_OBS_DIM+3] è‡ªèº«è§’è‰² one-hot [leader, pinned, normal]
        - [LOCAL_OBS_DIM+3:] é‚»å±…æ•°æ®ï¼ˆMAX_NEIGHBORS Ã— NEIGHBOR_FEAT_DIMï¼‰ï¼Œæ¯ä¸ªé‚»å±… 6 ç»´:
            - [0:2] é‚»å±…å¹¿æ’­çš„è‡ªèº«ä½ç½®ã€é€Ÿåº¦ï¼ˆå½’ä¸€åŒ–ï¼‰
            - [2:6] é‚»å±…éšå¹¿æ’­æºå¸¦çš„ leader ä¼°è®¡ï¼ˆpos/vel + seq_norm/age_normï¼‰

        æ³¨æ„ï¼šé‚»å±… role å·²ç§»é™¤ï¼›ä»…ä¿ç•™ self_roleã€‚
        """
        self._state_buffer.zero_()

        # 1) è‡ªèº«çŠ¶æ€
        self._state_buffer[:, :, 0] = self.positions / self.pos_limit
        self._state_buffer[:, :, 1] = self.velocities / self.vel_limit

        # 2) è‡ªèº« leader ä¼°è®¡ï¼ˆæ— è®°å¿†ç­–ç•¥å¿…é¡»æ˜¾å¼å¸¦å…¥ï¼‰
        denom_steps = float(MAX_STEPS) if float(MAX_STEPS) > 0 else 1.0

        leader_pos_norm = self.leader_est_pos / self.pos_limit
        leader_vel_norm = self.leader_est_vel / self.vel_limit

        seq = self.leader_est_seq
        seq_norm = torch.clamp(seq.float() / denom_steps, 0.0, 1.0)

        age = torch.where(
            seq >= 0,
            (self.leader_seq.unsqueeze(1) - seq).clamp(min=0).float(),
            torch.full_like(seq_norm, denom_steps),
        )
        age_norm = torch.clamp(age / denom_steps, 0.0, 1.0)

        self._state_buffer[:, :, 2] = leader_pos_norm
        self._state_buffer[:, :, 3] = leader_vel_norm
        self._state_buffer[:, :, 4] = seq_norm
        self._state_buffer[:, :, 5] = age_norm

        # 3) è‡ªèº«è§’è‰² one-hotï¼ˆå¯¹æ‰€æœ‰ç¯å¢ƒå¹¿æ’­ï¼‰
        self._state_buffer[:, :, LOCAL_OBS_DIM:LOCAL_OBS_DIM + SELF_ROLE_DIM] = self._role_onehot.unsqueeze(0)

        # 4) é‚»å±…æ•°æ®èµ·å§‹ä½ç½®
        neighbor_start = LOCAL_OBS_DIM + SELF_ROLE_DIM

        # é‚»å±…å¹¿æ’­çš„è‡ªèº«çŠ¶æ€ï¼ˆå½’ä¸€åŒ–ï¼‰
        broadcast_pos_norm = self.last_broadcast_pos / self.pos_limit  # (E, A)
        broadcast_vel_norm = self.last_broadcast_vel / self.vel_limit  # (E, A)

        # é‚»å±…å¹¿æ’­æºå¸¦çš„ leader ä¼°è®¡ï¼ˆå½’ä¸€åŒ– + æ–°é²œåº¦ï¼‰
        b_leader_pos_norm = self.last_broadcast_leader_pos / self.pos_limit
        b_leader_vel_norm = self.last_broadcast_leader_vel / self.vel_limit

        b_seq = self.last_broadcast_leader_seq
        b_seq_safe = torch.where(b_seq >= 0, b_seq.float(), torch.zeros_like(b_seq.float()))
        b_seq_norm = torch.clamp(b_seq_safe / denom_steps, 0.0, 1.0)

        b_age = torch.where(
            b_seq >= 0,
            (self.leader_seq.unsqueeze(1) - b_seq).clamp(min=0).float(),
            torch.full_like(b_seq_norm, denom_steps),
        )
        b_age_norm = torch.clamp(b_age / denom_steps, 0.0, 1.0)

        # padded indices/mask: (A, K)
        padded_idx = self._padded_neighbor_indices  # long
        valid_mask = self._neighbor_valid_mask      # bool

        # æ‰©å±•åˆ°æ‰¹é‡ç»´åº¦
        idx = padded_idx.unsqueeze(0).expand(self.num_envs, -1, -1)          # (E, A, K)
        valid = valid_mask.unsqueeze(0).expand(self.num_envs, -1, -1)        # (E, A, K)

        # ç”¨ dim=1 gatherï¼šæŠŠ (E, A, K) çš„ç´¢å¼•æ‹‰å¹³ä¸º (E, A*K)ï¼Œgather åå† reshape å›æ¥ã€‚
        idx_flat = idx.reshape(self.num_envs, -1)  # (E, A*K)

        neighbor_pos = broadcast_pos_norm.gather(1, idx_flat).view(self.num_envs, self.num_agents, MAX_NEIGHBORS)
        neighbor_vel = broadcast_vel_norm.gather(1, idx_flat).view(self.num_envs, self.num_agents, MAX_NEIGHBORS)

        neighbor_leader_pos = b_leader_pos_norm.gather(1, idx_flat).view(self.num_envs, self.num_agents, MAX_NEIGHBORS)
        neighbor_leader_vel = b_leader_vel_norm.gather(1, idx_flat).view(self.num_envs, self.num_agents, MAX_NEIGHBORS)
        neighbor_leader_seq = b_seq_norm.gather(1, idx_flat).view(self.num_envs, self.num_agents, MAX_NEIGHBORS)
        neighbor_leader_age = b_age_norm.gather(1, idx_flat).view(self.num_envs, self.num_agents, MAX_NEIGHBORS)

        # å°† padded çš„æ— æ•ˆé‚»å±…ç½®é›¶ï¼Œä¿æŒä¸æ—§å®ç°ä¸€è‡´ï¼ˆæ— é‚»å±…=å…¨ 0 ç‰¹å¾ï¼‰
        valid_f = valid.to(dtype=neighbor_pos.dtype)
        neighbor_pos = neighbor_pos * valid_f
        neighbor_vel = neighbor_vel * valid_f
        neighbor_leader_pos = neighbor_leader_pos * valid_f
        neighbor_leader_vel = neighbor_leader_vel * valid_f
        neighbor_leader_seq = neighbor_leader_seq * valid_f
        neighbor_leader_age = neighbor_leader_age * valid_f

        # å†™å…¥ state buffer
        neighbor_feat = self._state_buffer[:, :, neighbor_start:].view(
            self.num_envs, self.num_agents, MAX_NEIGHBORS, NEIGHBOR_FEAT_DIM
        )
        neighbor_feat[:, :, :, 0] = neighbor_pos
        neighbor_feat[:, :, :, 1] = neighbor_vel
        neighbor_feat[:, :, :, 2] = neighbor_leader_pos
        neighbor_feat[:, :, :, 3] = neighbor_leader_vel
        neighbor_feat[:, :, :, 4] = neighbor_leader_seq
        neighbor_feat[:, :, :, 5] = neighbor_leader_age

        # è®­ç»ƒå¾ªç¯é‡Œä¼šæŠŠ state ä¿å­˜åˆ° replay bufferï¼›ä¸ºäº†é¿å…å’Œå†…éƒ¨ buffer å‘ç”Ÿåˆ«åé—®é¢˜ï¼Œè¿™é‡Œä»è¿”å› clone
        return self._state_buffer.clone()
    
    def _scale_reward_batch(self, reward):
        """æ‰¹é‡å¥–åŠ±ç¼©æ”¾"""
        if self.use_soft_scaling:
            mid = (self.reward_max + self.reward_min) / 2
            scale = (self.reward_max - self.reward_min) / 2
            normalized = (reward - mid) / (scale + 1e-8)
            return mid + scale * torch.tanh(normalized)
        else:
            return torch.clamp(reward, self.reward_min, self.reward_max)
    
    def step(self, action):
        """æ‰§è¡Œä¸€æ­¥"""
        self.t += DT
        
        # ğŸ”§ æ›´æ–°é¢†å¯¼è€…ï¼ˆä½¿ç”¨æ¯ä¸ªç¯å¢ƒç‹¬ç«‹çš„åŠ¨åŠ›å­¦å‚æ•°ï¼‰
        leader_pos, leader_vel = self._leader_state_batch(self.t)
        self.positions[:, 0] = leader_pos
        self.velocities[:, 0] = leader_vel

        # leader æ¯æ­¥éƒ½ä¼šâ€œå¹¿æ’­â€è‡ªèº«çœŸå®çŠ¶æ€
        self.last_broadcast_pos[:, 0] = leader_pos
        self.last_broadcast_vel[:, 0] = leader_vel

        # ==================== leader gossipï¼šleader è‡ªèº«äº§ç”Ÿæ–°åºåˆ—å· ====================
        self.leader_seq += 1

        # leader è‡ªèº«çš„ leader ä¼°è®¡æ’ç­‰äºçœŸå€¼ï¼Œseq ä¹Ÿæ’ä¸ºæœ€æ–°
        self.leader_est_pos[:, 0] = leader_pos
        self.leader_est_vel[:, 0] = leader_vel
        self.leader_est_seq[:, 0] = self.leader_seq

        # leader å¹¿æ’­åŒ…é‡Œæºå¸¦çš„ leader ä¿¡æ¯ä¹Ÿæ’ä¸ºçœŸå€¼
        self.last_broadcast_leader_pos[:, 0] = leader_pos
        self.last_broadcast_leader_vel[:, 0] = leader_vel
        self.last_broadcast_leader_seq[:, 0] = self.leader_seq
        
        # è§£æåŠ¨ä½œ
        # ğŸ”§ Actor è¾“å‡ºçš„ç¬¬ 0 ç»´å·²ç»æŒ‰ V_SCALE ç¼©æ”¾è¿‡ï¼Œè¿™é‡Œä¸å†äºŒæ¬¡ç¼©æ”¾
        delta_v = action[:, :, 0]
        raw_threshold = action[:, :, 1]
        
        # é˜ˆå€¼æ˜ å°„
        normalized_threshold = raw_threshold / self.th_scale
        normalized_threshold = normalized_threshold.clamp(0.0, 1.0)
        threshold = self.threshold_min + (self.threshold_max - self.threshold_min) * normalized_threshold
        threshold = threshold.clamp(min=max(0.001, self.threshold_min), 
                                     max=min(self.threshold_max, 1.0))
        
        # æ— æ¨¡å‹åŠ¨åŠ›å­¦
        follower_vel = self.velocities[:, 1:]
        follower_pos = self.positions[:, 1:]
        
        new_vel = follower_vel + delta_v
        new_vel = torch.clamp(new_vel, -self.vel_limit, self.vel_limit)
        
        new_pos = follower_pos + new_vel * DT
        new_pos = torch.clamp(new_pos, -self.pos_limit, self.pos_limit)
        
        self.positions[:, 1:] = new_pos
        self.velocities[:, 1:] = new_vel
        
        # äº‹ä»¶è§¦å‘é€šä¿¡
        trigger_error = torch.abs(new_pos - self.last_broadcast_pos[:, 1:])
        is_triggered = trigger_error > threshold
        
        self.last_broadcast_pos[:, 1:] = torch.where(
            is_triggered, self.positions[:, 1:], self.last_broadcast_pos[:, 1:]
        )
        self.last_broadcast_vel[:, 1:] = torch.where(
            is_triggered, self.velocities[:, 1:], self.last_broadcast_vel[:, 1:]
        )

        # ==================== leader gossipï¼šå¹¿æ’­åŒ…æºå¸¦ leader ä¿¡æ¯ï¼ˆseq+age ç”± seq æ¨å¯¼ï¼‰ ====================
        # follower è§¦å‘é€šä¿¡æ—¶ï¼ŒåŒæ—¶å¹¿æ’­â€œè‡ªå·±å½“å‰æŒæ¡çš„ leader ä¼°è®¡â€ï¼ˆpos/vel + seqï¼‰
        trigger_full = torch.zeros(self.num_envs, self.num_agents, dtype=torch.bool, device=DEVICE)
        trigger_full[:, 1:] = is_triggered

        self.last_broadcast_leader_pos = torch.where(trigger_full, self.leader_est_pos, self.last_broadcast_leader_pos)
        self.last_broadcast_leader_vel = torch.where(trigger_full, self.leader_est_vel, self.last_broadcast_leader_vel)
        self.last_broadcast_leader_seq = torch.where(trigger_full, self.leader_est_seq, self.last_broadcast_leader_seq)

        # ==================== leader gossipï¼šä»é‚»å±…å¹¿æ’­åŒ…å¸æ”¶æ›´æ–°ï¼ˆmax seq èƒœå‡ºï¼‰ ====================
        padded_idx = self._padded_neighbor_indices  # (A, K)
        valid_mask = self._neighbor_valid_mask      # (A, K)

        idx = padded_idx.unsqueeze(0).expand(self.num_envs, -1, -1)          # (E, A, K)
        valid = valid_mask.unsqueeze(0).expand(self.num_envs, -1, -1)        # (E, A, K)
        idx_flat = idx.reshape(self.num_envs, -1)                             # (E, A*K)

        n_seq = self.last_broadcast_leader_seq.gather(1, idx_flat).view(self.num_envs, self.num_agents, MAX_NEIGHBORS)
        n_seq = torch.where(valid, n_seq, torch.full_like(n_seq, -1))
        seq_max, argmax = n_seq.max(dim=2)  # (E, A)

        # åªåœ¨æ”¶åˆ°â€œæ›´å¤§ seqâ€çš„æƒ…å†µä¸‹æ›´æ–°ï¼ˆå¯¹ä¹±åº/é‡å¤å¹¿æ’­ç¨³å®šï¼‰
        update_mask = (seq_max >= 0) & (seq_max > self.leader_est_seq)

        n_pos = self.last_broadcast_leader_pos.gather(1, idx_flat).view(self.num_envs, self.num_agents, MAX_NEIGHBORS)
        n_vel = self.last_broadcast_leader_vel.gather(1, idx_flat).view(self.num_envs, self.num_agents, MAX_NEIGHBORS)

        best_pos = n_pos.gather(2, argmax.unsqueeze(-1)).squeeze(-1)
        best_vel = n_vel.gather(2, argmax.unsqueeze(-1)).squeeze(-1)

        self.leader_est_pos = torch.where(update_mask, best_pos, self.leader_est_pos)
        self.leader_est_vel = torch.where(update_mask, best_vel, self.leader_est_vel)
        self.leader_est_seq = torch.where(update_mask, seq_max, self.leader_est_seq)
        
        # ==================== è®¡ç®—å¥–åŠ± ====================
        pos_error = torch.abs(self.positions[:, 1:] - self.positions[:, 0:1])
        vel_error = torch.abs(self.velocities[:, 1:] - self.velocities[:, 0:1])
        tracking_error = pos_error.mean(dim=1) + 0.5 * vel_error.mean(dim=1)

        # 1. è·Ÿè¸ªæƒ©ç½šï¼ˆä¸é¥±å’Œï¼‰ï¼šå¯¹è¯¯å·®åšå½’ä¸€åŒ–åä½¿ç”¨ log1p æƒ©ç½š
        # - éšè¯¯å·®å¢å¤§æŒç»­å˜å¤§ï¼ˆæ—  tanh é¥±å’Œï¼‰
        # - ä½¿ç”¨ pos/vel çš„ä¸Šé™åšå½’ä¸€åŒ–ï¼Œé¿å…æ•°å€¼å°ºåº¦è¿‡å¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®š
        pos_error_norm = pos_error.mean(dim=1) / self.pos_limit
        vel_error_norm = vel_error.mean(dim=1) / self.vel_limit
        tracking_error_norm = pos_error_norm + 0.5 * vel_error_norm
        tracking_penalty = -self.tracking_penalty_max * torch.log1p(tracking_error_norm * self.tracking_penalty_scale)
        
        # 2. æ”¹è¿›å¥–åŠ±
        improvement_bonus = torch.zeros_like(tracking_error)
        valid_mask = self._prev_error_valid
        if valid_mask.any():
            improvement = self._prev_error - tracking_error
            improvement_bonus = torch.where(
                valid_mask,
                torch.clamp(improvement * self.improvement_scale, 
                           -self.improvement_clip, self.improvement_clip),
                torch.zeros_like(improvement)
            )
        
        # æ›´æ–° prev_errorï¼ˆåŸä½å†™å…¥ï¼Œé¿å…æ¯æ­¥åˆ†é…æ–°å¼ é‡ï¼‰
        self._prev_error.copy_(tracking_error.detach())
        self._prev_error_valid[:] = True
        
        # 3. é€šä¿¡æƒ©ç½š
        comm_weight = torch.exp(-tracking_error * self.comm_weight_decay)
        comm_rate = is_triggered.float().mean(dim=1)
        comm_penalty = -comm_rate * self.comm_penalty_base * comm_weight
        
        # æ€»å¥–åŠ±
        raw_reward = tracking_penalty + improvement_bonus + comm_penalty
        rewards = self._scale_reward_batch(raw_reward)
        
        dones = torch.zeros(self.num_envs, dtype=torch.bool, device=DEVICE)
        
        infos = {
            'tracking_error': tracking_error,
            'comm_rate': comm_rate,
            'comm_weight': comm_weight,
            'leader_pos': self.positions[:, 0],
            'leader_vel': self.velocities[:, 0],
            'avg_follower_pos': self.positions[:, 1:].mean(dim=1),
            'threshold_mean': threshold.mean(),
            'tracking_penalty': tracking_penalty.mean(),
            'improvement_bonus': improvement_bonus.mean(),
            'comm_penalty': comm_penalty.mean(),
            # ğŸ”§ æ–°å¢ï¼šé¢†å¯¼è€…åŠ¨åŠ›å­¦å‚æ•°ä¿¡æ¯
            'leader_amplitude_mean': self.leader_amplitude.mean(),
            'leader_omega_mean': self.leader_omega.mean(),
        }
        
        return self._get_state_optimized(), rewards, dones, infos


class ModelFreeEnv:
    """å•ç¯å¢ƒç‰ˆæœ¬"""
    
    def __init__(self, topology):
        self.batched_env = BatchedModelFreeEnv(topology, num_envs=1)
        self.topology = topology
        self.num_agents = topology.num_agents
        self.num_followers = topology.num_followers
    
    @property
    def positions(self):
        return self.batched_env.positions[0]
    
    @property
    def velocities(self):
        return self.batched_env.velocities[0]
    
    @property
    def t(self):
        return self.batched_env.t[0].item()
    
    @property
    def leader_amplitude(self):
        return self.batched_env.leader_amplitude[0].item()
    
    @property
    def leader_omega(self):
        return self.batched_env.leader_omega[0].item()
    
    def get_global_state(self):
        """è·å–å…¨å±€çŠ¶æ€"""
        return self.batched_env.get_global_state()[0]
    
    def reset(self):
        state = self.batched_env.reset()
        return state[0]
    
    def step(self, action):
        action_batched = action.unsqueeze(0)
        states, rewards, dones, infos = self.batched_env.step(action_batched)
        info = {k: (v[0].item() if isinstance(v, torch.Tensor) and v.dim() > 0 else
                    v.item() if isinstance(v, torch.Tensor) else v)
                for k, v in infos.items()}
        return states[0], rewards[0].item(), dones[0].item(), info


# å…¼å®¹æ—§æ¥å£
BatchedLeaderFollowerEnv = BatchedModelFreeEnv
LeaderFollowerMASEnv = ModelFreeEnv